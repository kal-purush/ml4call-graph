{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    IMPORTING LIBS\n",
    "\"\"\"\n",
    "import inspect\n",
    "import sys\n",
    "import dgl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import argparse, json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dgl.function as fn\n",
    "MODEL_NAME = 'GraphSage'\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "\"\"\"\n",
    "    IMPORTING CUSTOM MODULES/METHODS\n",
    "\"\"\"\n",
    "# from nets.COLLAB_edge_classification.load_net import gnn_model # import all GNNS\n",
    "from nets.COLLAB_edge_classification.load_net import gnn_model\n",
    "from data.data import LoadData\n",
    "\"\"\"\n",
    "    GPU Setup\n",
    "\"\"\"\n",
    "def gpu_setup(use_gpu, gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print('cuda not available')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "use_gpu = False; gpu_id = -1; device = None # CPU\n",
    "# \"\"\"\n",
    "#     USER CONTROLS\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datset(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    print(\"[I] Finished loading.....\")\n",
    "    # print(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_parameter(MODEL_NAME, dataset):\n",
    "    \n",
    "#     MODEL_NAME = 'MF'\n",
    "    # MODEL_NAME = 'GatedGCN'\n",
    "    \n",
    "    n_heads = -1\n",
    "    edge_feat = False\n",
    "    pseudo_dim_MoNet = -1\n",
    "    kernel = -1\n",
    "    gnn_per_block = -1\n",
    "    embedding_dim = -1\n",
    "    pool_ratio = -1\n",
    "    n_mlp_GIN = -1\n",
    "    gated = False\n",
    "    self_loop = False\n",
    "    max_time = 12\n",
    "    layer_type = 'dgl'\n",
    "    num_embs = -1\n",
    "    pos_enc = True\n",
    "    #pos_enc = False\n",
    "    pos_enc_dim = 10\n",
    "\n",
    "    \n",
    "    if MODEL_NAME == 'MF':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.01; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=0; hidden_dim=256; out_dim=hidden_dim; num_embs=235868;\n",
    "    \n",
    "    if MODEL_NAME == 'MLP':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=80; out_dim=hidden_dim; dropout=0.0; readout='mean'; gated = False  # Change gated = True for Gated MLP model\n",
    "    \n",
    "    if MODEL_NAME == 'GCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=74; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GraphSage':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=10; hidden_dim=38; out_dim=hidden_dim; dropout=0.0; readout='mean'; layer_type='edgefeat'\n",
    "\n",
    "    if MODEL_NAME == 'GAT':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; n_heads=3; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'; layer_type='dgl'\n",
    "    \n",
    "    if MODEL_NAME == 'GIN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=60; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'MoNet':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=53; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GatedGCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=35; out_dim=hidden_dim; dropout=0.0; readout='mean'; edge_feat = False; layer_type='edgereprfeat'\n",
    "        \n",
    "    # generic new_params\n",
    "    net_params = {}\n",
    "    net_params['device'] = device\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['residual'] = True\n",
    "    net_params['hidden_dim'] = hidden_dim\n",
    "    net_params['out_dim'] = out_dim\n",
    "    num_classes = 1\n",
    "    net_params['n_classes'] = num_classes\n",
    "    net_params['n_heads'] = n_heads\n",
    "    net_params['L'] = L  # min L should be 2\n",
    "    net_params['readout'] = \"mean\"\n",
    "    net_params['layer_norm'] = True\n",
    "    net_params['batch_norm'] = True\n",
    "    net_params['in_feat_dropout'] = 0.0\n",
    "    net_params['dropout'] = 0.0\n",
    "    net_params['edge_feat'] = edge_feat\n",
    "    net_params['self_loop'] = self_loop\n",
    "    net_params['layer_type'] = layer_type\n",
    "    \n",
    "    # for MF\n",
    "    net_params['num_embs'] = num_embs\n",
    "    \n",
    "    # for MLPNet \n",
    "    net_params['gated'] = gated\n",
    "    \n",
    "    # specific for MoNet\n",
    "    net_params['pseudo_dim_MoNet'] = 2\n",
    "    net_params['kernel'] = 3\n",
    "    \n",
    "    # specific for GIN\n",
    "    net_params['n_mlp_GIN'] = 2\n",
    "    net_params['learn_eps_GIN'] = True\n",
    "    net_params['neighbor_aggr_GIN'] = 'sum'\n",
    "    \n",
    "    # specific for graphsage\n",
    "    net_params['sage_aggregator'] = 'maxpool'   \n",
    "    \n",
    "    # specific for pos_enc_dim\n",
    "    net_params['pos_enc'] = pos_enc\n",
    "    net_params['pos_enc_dim'] = pos_enc_dim\n",
    "\n",
    "    \n",
    "    params = {}\n",
    "    params['seed'] = seed\n",
    "    params['epochs'] = epochs\n",
    "    params['batch_size'] = batch_size\n",
    "    params['init_lr'] = init_lr\n",
    "    params['lr_reduce_factor'] = lr_reduce_factor \n",
    "    params['lr_schedule_patience'] = lr_schedule_patience\n",
    "    params['min_lr'] = min_lr\n",
    "    params['weight_decay'] = weight_decay\n",
    "    params['print_epoch_interval'] = 5\n",
    "    params['max_time'] = max_time\n",
    "\n",
    "    return net_params, params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(test_edges, test_pred, src_id, APPLICATION_NAME):\n",
    "\n",
    "    ROOT_PATH = \"../new/\"\n",
    "    df = pd.read_csv(ROOT_PATH+ APPLICATION_NAME+'_node.csv')\n",
    "    stmt_type=['FunctionDeclaration', 'ArrowFunctionExpression', 'FunctionExpression']\n",
    "    df1 = df[df.type.isin(stmt_type)]\n",
    "    # out_csv_file = open(\"candidates_csv/candidate_\"+APPLICATION_NAME+\"_\"+str(src_id)+\".csv\",\"w+\")\n",
    "    # out_csv_file.write(\"src,dst,score,file_name,start_line,name\\n\")\n",
    "    src_list =[]\n",
    "    dst_lst =[]\n",
    "    scores =[]\n",
    "    file_names =[]\n",
    "    start_lines = []\n",
    "    names =[]\n",
    "    \n",
    "    for i in range(len(test_edges)):\n",
    "        temp_df = df1[df1['new_id']==test_edges[i][1].item()]\n",
    "        # print(temp_df)\n",
    "        file_name = temp_df.iloc[0]['file_name']\n",
    "        start_line = temp_df.iloc[0]['start_line']\n",
    "        name = temp_df.iloc[0]['name']\n",
    "        if pd.isna(temp_df.iloc[0]['name']):\n",
    "            name= \"\"\n",
    "        # pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "        src_list.append(str(test_edges[i][0].item()))\n",
    "        dst_lst.append(str(test_edges[i][1].item()))\n",
    "        scores.append(float(test_pred[i].item()))\n",
    "        file_names.append(file_name)\n",
    "        start_lines.append(start_line)\n",
    "        names.append(name)\n",
    "        # out_csv_file.write(str(test_edges[i][0].item())+\",\"+str(test_edges[i][1].item())+\",\"+pred_score+\",\"+file_name+\",\"+str(start_line)+\",\"+name+\"\\n\")\n",
    "    \n",
    "    df = pd.DataFrame({'src':src_list, 'dst':dst_lst, 'score':scores, 'file_name':file_names, 'start_line':start_lines, 'name':names})\n",
    "    df = df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n",
    "    pred_scores = [\"{:.12f}\".format(i) for i in df['score'].tolist()]\n",
    "    df['score']=pred_scores\n",
    "    # print(df)\n",
    "    df.to_csv(\"candidates_csv/candidate_\"+APPLICATION_NAME+\"_\"+str(src_id)+\".csv\")\n",
    "\n",
    "    # out_csv_file.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_data(src_id):\n",
    "#     print(src_id)\n",
    "#     ROOT_PATH = \"new_dataset/new/\"\n",
    "#     df = pd.read_csv(ROOT_PATH+ APPLICATION_NAME+'_node.csv')\n",
    "#     stmt_type=['FunctionDeclaration', 'ArrowFunctionExpression', 'FunctionExpression']\n",
    "#     df1 = df[df.type.isin(stmt_type)]\n",
    "#     test_neg_id = df1['new_id'].tolist()\n",
    "#     src = [src_id]*len(test_neg_id)\n",
    "#     d={'src':src, 'dst':test_neg_id}\n",
    "#     test_df = pd.DataFrame(d)\n",
    "#     # print(len(test_neg_id), d)\n",
    "#     test_edges = torch.from_numpy(test_df.to_numpy())\n",
    "#     return test_edges\n",
    "\n",
    "\n",
    "def get_test_data(src_id, for_true_negative=False, APPLICATION_NAME=\"\"):\n",
    "    # print(src_id)\n",
    "    ROOT_PATH = \"../prune_new/\"\n",
    "    df = pd.read_csv(ROOT_PATH+ APPLICATION_NAME+'_node.csv')\n",
    "    d = dict()\n",
    "    f = open('../full_ast/'+APPLICATION_NAME+'_import_dict.json')\n",
    "    data = json.load(f)\n",
    "    u=[]\n",
    "    v=[]\n",
    "    temp_df_src = df[df['new_id']==src_id]\n",
    "    file_name = temp_df_src.iloc[0]['file_name']\n",
    "    lst = data[file_name]\n",
    "    new_lst = []\n",
    "    new_lst.append(file_name)\n",
    "    for x in lst:\n",
    "        if \"lodash/internal\" in x:\n",
    "            x = x.replace(\"lodash/internal\",\"lodash/.internal\")\n",
    "        new_lst.append(x)\n",
    "    # print(new_lst)\n",
    "    stmt_type=['FunctionDeclaration', 'ArrowFunctionExpression', 'FunctionExpression']\n",
    "    dst_df = df[(df.type.isin(stmt_type)) & (df.file_name.isin(new_lst))]\n",
    "    if for_true_negative:\n",
    "        return dst_df\n",
    "    # print(dst_df['file_name'])\n",
    "    # print(file_name, \"====>\",  len(dst_df))\n",
    "    # for x in range(len(dst_df)):\n",
    "    #      print(dst_df.iloc[x])\n",
    "    test_neg_id = dst_df['new_id'].tolist()\n",
    "    done_list={}\n",
    "    for node in test_neg_id:\n",
    "        if (src_id,node) not in done_list:\n",
    "                u.append(src_id)\n",
    "                v.append(node)\n",
    "                done_list[(src_id,node)]=True\n",
    "\n",
    "    d={'src':u, 'dst':v}\n",
    "    test_df = pd.DataFrame(d)\n",
    "#     print(test_df)\n",
    "    test_edges = torch.from_numpy(test_df.to_numpy())\n",
    "    return test_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_test_data(8439, APPLICATION_NAME='lodash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIEW MODEL PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_model_param(MODEL_NAME, net_params):\n",
    "    # print(net_params)\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    total_param = 0\n",
    "    # print(\"MODEL DETAILS:\\n\")\n",
    "    # print(model)\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    # print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
    "    return total_param\n",
    "\n",
    "tim1 = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDF(APPLICATION_NAME):\n",
    "    df = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(MODEL_NAME, dataset, DATASET_NAME):\n",
    "    net_params, params = define_parameter(MODEL_NAME=MODEL_NAME, dataset=dataset)\n",
    "    config = {}\n",
    "    gpu = {}\n",
    "    gpu['use'] = use_gpu\n",
    "    gpu['id'] = gpu_id\n",
    "    config['gpu'] = gpu\n",
    "    # GNN model, dataset, out_dir\n",
    "    config['model'] = MODEL_NAME\n",
    "    config['dataset'] = DATASET_NAME\n",
    "    out_dir = 'out/debug/'\n",
    "    config['out_dir'] = out_dir\n",
    "    config['params'] = params\n",
    "    # network parameters\n",
    "    config['net_params'] = net_params\n",
    "    params = config['params']\n",
    "    DATASET_NAME = config['dataset']\n",
    "    device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
    "    out_dir = config['out_dir']\n",
    "    MODEL_NAME = config['model']\n",
    "    net_params = config['net_params']\n",
    "    net_params['device'] = device\n",
    "    net_params['gpu_id'] = config['gpu']['id']\n",
    "    net_params['batch_size'] = params['batch_size']\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['n_classes'] = 1  # binary prediction\n",
    "    net_params['total_param'] = view_model_param(MODEL_NAME, net_params)\n",
    "    \n",
    "    return net_params, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME):\n",
    "    t0 = time.time()    \n",
    "    DATASET_NAME = dataset.name\n",
    "\n",
    "    if MODEL_NAME in ['GatedGCN']:\n",
    "        if net_params['pos_enc']:\n",
    "            print(\"[!] Adding graph positional encoding\",net_params['pos_enc_dim'])\n",
    "            dataset._add_positional_encodings(net_params['pos_enc_dim'])\n",
    "            print('Time PE:',time.time()-t0)\n",
    "\n",
    "    graph = dataset.graph\n",
    "    evaluator=\"\"\n",
    "    train_edges, val_edges, val_edges_neg, test_edges, test_edges_neg = dataset.train_edges, dataset.val_edges, dataset.val_edges_neg, dataset.test_edges, dataset.test_edges_neg\n",
    "    device = net_params['device']\n",
    "    random.seed(params['seed'])\n",
    "    np.random.seed(params['seed'])\n",
    "    torch.manual_seed(params['seed'])\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(params['seed'])\n",
    "\n",
    "    print(\"Graph: \", graph)\n",
    "    print(\"Training Edges: \", len(train_edges))\n",
    "    print(\"Validation Edges: \", len(val_edges) + len(val_edges_neg))\n",
    "    print(\"Test Edges: \", len(test_edges) + len(test_edges_neg))\n",
    "\n",
    "    print(net_params)\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    model = model.to(device)\n",
    "    out_dir = 'out/debug/'\n",
    "    PATH = out_dir + 'checkpoints/' + MODEL_NAME + \"_NEW_DATASET--\" + APPLICATION_NAME + \"/RUN_/epoch_\"+str(EPOC_NUMBER)+\".pkl\"\n",
    "    t = torch.load(PATH)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "#     print(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                        factor=params['lr_reduce_factor'],\n",
    "                                                        patience=params['lr_schedule_patience'],\n",
    "                                                        verbose=True)\n",
    "\n",
    "    return model, graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EPOC_Number(PATH):\n",
    "    file_path = PATH+\"/ROC_CURVE/*\"\n",
    "    project_list = glob.glob(file_path)\n",
    "    max_ = -1\n",
    "    for line in project_list:\n",
    "        index = line.rfind(\"_\")\n",
    "        last_index = line.rfind(\".png\")\n",
    "        number = int(line[index+1:last_index])\n",
    "        max_ = max(max_, number)\n",
    "    # print(max_)\n",
    "    return max_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(rank_list,APPLICATION_NAME):\n",
    "    # print(rank_list)\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # plt.hist(rank_list, color = 'blue', edgecolor = 'black',\n",
    "    #          bins = int(max(rank_list)/5))\n",
    "\n",
    "    # seaborn histogram\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.distplot(rank_list, hist=True, kde=False, \n",
    "                bins=int(max(rank_list)/2), color = 'blue',\n",
    "                hist_kws={'edgecolor':'black'})\n",
    "    # Add labels\n",
    "\n",
    "    plt.title('Histogram of Candidate Ranking')\n",
    "    plt.xlabel('Ranking')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(\"candidate_figures/positive_\"+APPLICATION_NAME+\".pdf\")\n",
    "    # plt.savefig(\"ms_0.7.0.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CANDIDATE FOR MISSED EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_network_for_missed_edge(model, device, graph, test_edges,\n",
    "                     batch_size, DATASET_NAME=\"\", MODEL_NAME=\"\", SOURCE_NODE=0, DST_NODE=0, APPLICATION_NAME=\"\"):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph = graph.to(device)\n",
    "        x = graph.ndata['feat'].to(device)\n",
    "        e = graph.edata['feat'].to(device).float()\n",
    "        try:\n",
    "            x_pos_enc = graph.ndata['pos_enc'].to(device)\n",
    "            h = model(graph, x, e, x_pos_enc) \n",
    "        except:\n",
    "            h = model(graph, x, e)\n",
    "\n",
    "        test_edges = test_edges.to(device)\n",
    "\n",
    "        test_preds = []\n",
    "        for perm in DataLoader(range(test_edges.size(0)), batch_size):\n",
    "            edge = test_edges[perm].t()\n",
    "            # print(\"edge ==> \",edge, len(edge))\n",
    "            test_preds += [model.edge_predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "        # print(test_preds)\n",
    "        if len(test_edges)==1:\n",
    "            t= test_preds[0]\n",
    "            t =np.expand_dims(t,0)\n",
    "            t = torch.tensor(t)\n",
    "            test_preds = [t]\n",
    "        test_pred = torch.cat(test_preds, dim=0)\n",
    "        \n",
    "    # write_to_file(test_edges=test_edges, test_pred=test_pred, src_id=SOURCE_NODE, APPLICATION_NAME=APPLICATION_NAME)\n",
    "\n",
    "    src=[]\n",
    "    dst=[]\n",
    "    scores = []\n",
    "    for i in range(len(test_edges)):\n",
    "        pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "        s = int(test_edges[i][0].item())\n",
    "        d = int(test_edges[i][1].item())\n",
    "        src.append(s)\n",
    "        dst.append(d)\n",
    "        scores.append(pred_score)\n",
    "\n",
    "    d = {\"src\": src, \"dst\":dst, \"score\":scores}\n",
    "    df = pd.DataFrame(d)\n",
    "    df = df.sort_values(by='score', ascending=False, na_position='first').reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rank(df, SOURCE_NODE, node_df):\n",
    "    df['score']=df.score.replace('',np.nan).astype(float)\n",
    "    temp_df = df[(df[\"score\"]>=.005)]\n",
    "    temp_df = df\n",
    "    if len(temp_df)>0:\n",
    "        should_print = False\n",
    "        for i in range(len(temp_df)):\n",
    "            src = int(temp_df.iloc[i]['src'])\n",
    "            dst = int(temp_df.iloc[i]['dst'])\n",
    "            score = temp_df.iloc[i]['score']\n",
    "\n",
    "            df1 = node_df[node_df['new_id']==src]\n",
    "            # print(df1)\n",
    "            src_file_name = df1.iloc[0]['file_name']\n",
    "            # name = df1.iloc[0]['name']\n",
    "            src_start_line = df1.iloc[0]['start_line']\n",
    "            # print(src_start_line)\n",
    "            src_start_column = df1.iloc[0]['start_column']\n",
    "\n",
    "            if src_file_name =='/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/cloneWith.js':\n",
    "                should_strt_line = 37\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/nthArg.js':\n",
    "                should_strt_line = 21\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/reduceRight.js':\n",
    "                should_strt_line = 40\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/keyBy.js':\n",
    "                should_strt_line = 28\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/wrap.js':\n",
    "                should_strt_line = 44\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/divide.test.js':\n",
    "                should_strt_line = 6\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/rearg.js':\n",
    "                should_strt_line = 68\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js':\n",
    "                should_strt_line = 387\n",
    "                # should_strt_line = 479\n",
    "            if src_file_name == '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/cloneDeep.js':\n",
    "                should_strt_line = 25\n",
    "            \n",
    "            if src_start_line == should_strt_line:\n",
    "                should_print = True\n",
    "                df1 = node_df[node_df['new_id']==dst]\n",
    "                # print(df1)\n",
    "                file_name = df1.iloc[0]['file_name']\n",
    "                name = df1.iloc[0]['name']\n",
    "                start_line = df1.iloc[0]['start_line']\n",
    "                start_column = df1.iloc[0]['start_column']\n",
    "                print(src_file_name, src_start_line, src_start_column,'==========>', file_name, name, start_line, start_column, '=======>', score)\n",
    "        if should_print: \n",
    "            print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_for_missed_call_site(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME):\n",
    "    df =pd.read_csv(\"dynamic_edges/dynamic_edges_\"+APPLICATION_NAME+\".csv\")\n",
    "    df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    missed_df = pd.read_csv(\"missed_edges/\"+APPLICATION_NAME+\"_missed_call_site_ids.csv\")\n",
    "    ids = missed_df['id'].tolist()\n",
    "    src=df['src'].tolist()\n",
    "    missed_lst = [x for x in ids if x not in src]\n",
    "    lst = missed_lst\n",
    "\n",
    "    node_df_org = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    node_df = node_df_org[node_df_org['new_id'].isin(lst)].reset_index(drop=True)\n",
    "\n",
    "    include = ['/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/cloneWith.js', '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/nthArg.js', \n",
    "                '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/keyBy.js',\n",
    "                '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/wrap.js','/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/divide.test.js'\n",
    "                '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/test/rearg.js'\n",
    "                '/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/cloneDeep.js']\n",
    "    include = ['/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/lodash/cloneWith.js']\n",
    "    include = ['/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js']\n",
    "    for i in range(len(node_df)):\n",
    "        file_name = node_df.iloc[i]['file_name']\n",
    "        name = node_df.iloc[i]['name']\n",
    "        start_line = node_df.iloc[i]['start_line']\n",
    "        start_column = node_df.iloc[i]['start_column']\n",
    "        src_id = node_df.iloc[i]['new_id']\n",
    "        # print(file_name, name, start_line, start_column, src_id)\n",
    "        if file_name in include:\n",
    "            test_edges = get_test_data(src_id=src_id, APPLICATION_NAME=APPLICATION_NAME)\n",
    "            # print(len(test_edges))\n",
    "            if len(test_edges) > 0:\n",
    "                df = evaluate_network_for_missed_edge(\n",
    "                        model, device, graph, test_edges, params['batch_size'], DATASET_NAME=DATASET_NAME, MODEL_NAME=MODEL_NAME, SOURCE_NODE=src_id, APPLICATION_NAME=APPLICATION_NAME)\n",
    "                # print(df)\n",
    "                print_rank(df,src_id, node_df_org)\n",
    "\n",
    "                # print(\"\\n\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate for True Negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/fresh_start/prune+bidirectional+semantic_edge\n",
      "\u001b[97m ------------------------------------------------------------------\n",
      "\u001b[97m  formula-parser\n",
      "\u001b[97m ------------------------------------------------------------------\n",
      "174\n",
      "[I] Loading data (notebook) ...\n",
      "[I] Loading dataset formula-parser...\n",
      "New node ====>  2073  New edge======>  4010\n",
      "y ==>  41654 41654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/fresh_start/prune+bidirectional+semantic_edge/data/NewDataset.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(targets, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Finished loading.\n",
      "[I] Data load time: 79.5208s\n",
      "[I] Finished loading.....\n",
      "cuda not available\n",
      "[!] Adding graph positional encoding 10\n",
      "Time PE: 1.4452342987060547\n",
      "Graph:  Graph(num_nodes=41654, num_edges=210464,\n",
      "      ndata_schemes={'x_one_hot': Scheme(shape=(47,), dtype=torch.int64), 'x': Scheme(shape=(1,), dtype=torch.int64), 'param_len_one_hot': Scheme(shape=(9,), dtype=torch.int64), 'param_len': Scheme(shape=(1,), dtype=torch.int64), 'args_len_one_hot': Scheme(shape=(9,), dtype=torch.int64), 'args_len': Scheme(shape=(1,), dtype=torch.int64), 'name_one_hot': Scheme(shape=(2075,), dtype=torch.int64), 'name': Scheme(shape=(1,), dtype=torch.int64), 'feat': Scheme(shape=(2140,), dtype=torch.int64), 'pos_enc': Scheme(shape=(10,), dtype=torch.float32)}\n",
      "      edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.int64)})\n",
      "Training Edges:  91099\n",
      "Validation Edges:  19734\n",
      "Test Edges:  512\n",
      "{'device': device(type='cpu'), 'in_dim': 2140, 'in_dim_edge': 1, 'residual': True, 'hidden_dim': 35, 'out_dim': 35, 'n_classes': 1, 'n_heads': -1, 'L': 5, 'readout': 'mean', 'layer_norm': True, 'batch_norm': True, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'edge_feat': False, 'self_loop': False, 'layer_type': 'edgereprfeat', 'num_embs': -1, 'gated': False, 'pseudo_dim_MoNet': 2, 'kernel': 3, 'n_mlp_GIN': 2, 'learn_eps_GIN': True, 'neighbor_aggr_GIN': 'sum', 'sage_aggregator': 'maxpool', 'pos_enc': True, 'pos_enc_dim': 10, 'gpu_id': -1, 'batch_size': 32768, 'total_param': 110705}\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "# APPLICATION_NAME = \"lodash\"\n",
    "\n",
    "\n",
    "MODEL_NAME = 'GatedGCN'\n",
    "\n",
    "\n",
    "# to_do_list = ['lodash', 'formula-parser', 'mathjs' ]\n",
    "# app_list = ['lodash', 'formula-parser', 'mathjs' ]\n",
    "\n",
    "to_do_list = ['formula-parser', 'lodash', 'express','js-yaml']\n",
    "app_list = ['formula-parser', 'lodash', 'express','js-yaml']\n",
    "\n",
    "to_do_list = ['formula-parser']\n",
    "app_list = ['formula-parser']\n",
    "\n",
    "# print(os.getcwd())\n",
    "# if \"with_dynamic_edge\" not in str(os.getcwd()):\n",
    "#     os.chdir('with_dynamic_edge/')\n",
    "# print(os.getcwd())\n",
    "for i in range(len(to_do_list)):\n",
    "    APPLICATION_NAME = app_list[i]\n",
    "\n",
    "    # df = pd.read_csv('../csv_files/id_files/'+ APPLICATION_NAME+'_missed_call_site_ids.csv')\n",
    "    # ids = df['id'].tolist()\n",
    "\n",
    "    # dynamic_edges = pd.read_csv('../with_dynamic_edge/dynamic_edges/dynamic_edges_lodash.csv')\n",
    "    # dynamic_edges = dynamic_edges[dynamic_edges['src']==ids[0]]\n",
    "\n",
    "    DATASET_NAME = 'NEW_DATASET--'+APPLICATION_NAME\n",
    "    print(\"\\033[97m ------------------------------------------------------------------\")\n",
    "    print(\"\\033[97m \", APPLICATION_NAME)\n",
    "    print(\"\\033[97m ------------------------------------------------------------------\")\n",
    "    # print(\"[I] Loading data (notebook) ...\")\n",
    "    node_df = LoadDF(APPLICATION_NAME)\n",
    "    # print(node_df)\n",
    "    # print(\"[I] Finished loading.\")\n",
    "    PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "    EPOC_NUMBER = get_EPOC_Number(PATH=PATH)\n",
    "    # EPOC_NUMBER = 149\n",
    "    print(EPOC_NUMBER)\n",
    "    dataset = load_datset(DATASET_NAME)\n",
    "    net_params, params = set_parameters(MODEL_NAME, dataset, DATASET_NAME)\n",
    "    model, graph = train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME)\n",
    "    # print(model, graph)\n",
    "    rank_list = get_candidate_for_missed_call_site(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME)\n",
    "    # plot_graph(rank_list, APPLICATION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js lex 782 4 =======> 0.903063178062\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js popStack 317 4 =======> 0.873331427574\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 652 11 =======> 0.839535295963\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 724 5 =======> 0.363179415464\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js parseError 264 12 =======> 0.291295111179\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js trace 76 21 =======> 0.290343612432\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 569 6 =======> 0.257925361395\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js begin 792 6 =======> 0.220577895641\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 546 6 =======> 0.149885714054\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 323 14 =======> 0.139056101441\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js _currentRules 807 14 =======> 0.074227437377\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 630 10 =======> 0.033354230225\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js parseError 516 11 =======> 0.023186612874\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js locateNearestErrorRecoveryRule 356 12 =======> 0.011536064558\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 636 14 =======> 0.008828571066\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 625 5 =======> 0.003670979058\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js parse 273 7 =======> 0.002628733171\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 75 6 =======> 0.000776170229\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js anonymous 835 15 =======> 0.000674278534\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 525 9 =======> 0.000555735722\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js popState 797 9 =======> 0.000120743556\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 511 13 =======> 0.000112761991\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js topState 816 9 =======> 9.1570102e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js pushState 826 10 =======> 9.118436e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 610 7 =======> 7.6791664e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js anonymous 81 15 =======> 7.1436727e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js stateStackSize 831 15 =======> 6.6942186e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 645 13 =======> 6.5488552e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 604 5 =======> 3.525315e-06\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 71 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js Parser 920 7 =======> 4.81e-10\n",
      "\n",
      "\n",
      "\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 652 11 =======> 0.955133497715\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js lex 782 4 =======> 0.757024347782\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 569 6 =======> 0.599263072014\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js popStack 317 4 =======> 0.595652461052\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 546 6 =======> 0.404234230518\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js begin 792 6 =======> 0.335656344891\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js parseError 264 12 =======> 0.184514954686\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 630 10 =======> 0.139913335443\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 724 5 =======> 0.125253081322\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js trace 76 21 =======> 0.123271182179\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 323 14 =======> 0.10931712389\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 625 5 =======> 0.037570219487\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 636 14 =======> 0.03511371091\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js parseError 516 11 =======> 0.02479717508\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js _currentRules 807 14 =======> 0.007463422604\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js locateNearestErrorRecoveryRule 356 12 =======> 0.006316211075\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js parse 273 7 =======> 0.001705181785\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 525 9 =======> 0.001480386825\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 75 6 =======> 0.000816671993\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js anonymous 835 15 =======> 0.000608996954\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js topState 816 9 =======> 0.000410159788\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 645 13 =======> 0.000301464461\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js pushState 826 10 =======> 0.000274487917\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js popState 797 9 =======> 7.9773818e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 511 13 =======> 7.9426092e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 610 7 =======> 7.2164483e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js anonymous 81 15 =======> 1.8589115e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js stateStackSize 831 15 =======> 1.0651902e-05\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js nan 604 5 =======> 4.903589e-06\n",
      "/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js 387 107 ==========> /Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/src/grammar-parser/grammar-parser.js Parser 920 7 =======> 7.8e-11\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_candidate_for_missed_call_site(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLICATION_NAME = 'formula-parser'\n",
    "df =pd.read_csv(\"dynamic_edges/dynamic_edges_\"+APPLICATION_NAME+\".csv\")\n",
    "df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "\n",
    "\n",
    "missed_df = pd.read_csv(\"../csv_files/id_files/\"+APPLICATION_NAME+\"_missed_call_site_ids.csv\")\n",
    "# missed_df = missed_df.drop_duplicates(subset=['id'], keep='first').reset_index(drop=True)\n",
    "ids = missed_df['id'].tolist()\n",
    "\n",
    "src=df['src'].tolist()\n",
    "# len(src)\n",
    "\n",
    "missed_lst = [x for x in ids if x not in src]\n",
    "# lst = random.sample(missed_lst, 50)\n",
    "lst = missed_lst\n",
    "# len(ids), len(src), len(missed_lst)\n",
    "# df = df[~df['src'].isin(ids)]\n",
    "# df = df.sample(n=20)\n",
    "# df\n",
    "node_df = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "node_df = node_df[node_df['new_id'].isin(lst)].reset_index(drop=True)\n",
    "# print(node_df)\n",
    "# exclude = []\n",
    "exclude = ['toUpperCase','require','forEach','copySync','resolve','replace','Error','reduce','toString','push','fn','bind','on','done','split','slice','substr',\n",
    "'match','log','matrix','bignumber','throws','map', 'func', 'constant','each','assign','toLowerCase']\n",
    "lst=[]\n",
    "for i in range(len(node_df)):\n",
    "    file_name = node_df.iloc[i]['file_name']\n",
    "    name = node_df.iloc[i]['name']\n",
    "    start_line = node_df.iloc[i]['start_line']\n",
    "    start_column = node_df.iloc[i]['start_column']\n",
    "    # if name not in exclude:\n",
    "    lst.append(name)\n",
    "    if name not in exclude and \"/dist/\" not in file_name:\n",
    "        print(file_name, name, start_line, start_column)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "filepath = \"dynamic_edges/*\"\n",
    "project_list = glob.glob(filepath)\n",
    "project_list\n",
    "# lst=[]\n",
    "for x in project_list:\n",
    "    print(x)\n",
    "    index = x.rfind(\"_\")\n",
    "    last_index = x.rfind(\".csv\")\n",
    "    DATASET_NAME = x[index+1:last_index]\n",
    "    print(DATASET_NAME)\n",
    "    df = pd.read_csv(x)\n",
    "    df = df.drop_duplicates(subset=['src', 'dst'], keep='first').reset_index(drop=True)\n",
    "\n",
    "    func_df = pd.read_csv(\"../new/\"+DATASET_NAME+\"_function_edges.csv\")\n",
    "\n",
    "    new_df = df.merge(func_df, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "    print(len(df), len(func_df), len(new_df))\n",
    "    # print(df.shape)\n",
    "\n",
    "# print(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
