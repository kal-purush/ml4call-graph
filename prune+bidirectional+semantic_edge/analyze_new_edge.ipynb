{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ca17c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc5210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "# os.chdir('../')\n",
    "# print(os.getcwd())\n",
    "if \"with_dynamic_edge\" in str(os.getcwd()):\n",
    "    os.chdir('../')\n",
    "\"\"\"\n",
    "    IMPORTING LIBS\n",
    "\"\"\"\n",
    "import dgl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import argparse, json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dgl.function as fn\n",
    "MODEL_NAME = 'GraphSage'\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "\n",
    "\"\"\"\n",
    "    IMPORTING CUSTOM MODULES/METHODS\n",
    "\"\"\"\n",
    "# from nets.COLLAB_edge_classification.load_net import gnn_model # import all GNNS\n",
    "from nets.COLLAB_edge_classification.load_net import gnn_model\n",
    "from data.data import LoadData\n",
    "\"\"\"\n",
    "    GPU Setup\n",
    "\"\"\"\n",
    "def gpu_setup(use_gpu, gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print('cuda not available')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "use_gpu = False; gpu_id = -1; device = None # CPU\n",
    "# \"\"\"\n",
    "#     USER CONTROLS\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffe28c-9432-49d8-ad5b-40013c3f41de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842a3e7a-16a3-4cfb-8e1e-4f704ad8381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datset(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    print(\"[I] Finished loading.....\")\n",
    "    # print(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75672b-cd34-4ddb-baca-63d14825afd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DEFINE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6552916-1712-4568-826f-cd47839a34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_parameter(MODEL_NAME, dataset):\n",
    "    \n",
    "#     MODEL_NAME = 'MF'\n",
    "    # MODEL_NAME = 'GatedGCN'\n",
    "    \n",
    "    n_heads = -1\n",
    "    edge_feat = False\n",
    "    pseudo_dim_MoNet = -1\n",
    "    kernel = -1\n",
    "    gnn_per_block = -1\n",
    "    embedding_dim = -1\n",
    "    pool_ratio = -1\n",
    "    n_mlp_GIN = -1\n",
    "    gated = False\n",
    "    self_loop = False\n",
    "    max_time = 12\n",
    "    layer_type = 'dgl'\n",
    "    num_embs = -1\n",
    "    pos_enc = True\n",
    "    #pos_enc = False\n",
    "    pos_enc_dim = 10\n",
    "\n",
    "    \n",
    "    if MODEL_NAME == 'MF':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.01; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=0; hidden_dim=256; out_dim=hidden_dim; num_embs=235868;\n",
    "    \n",
    "    if MODEL_NAME == 'MLP':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=80; out_dim=hidden_dim; dropout=0.0; readout='mean'; gated = False  # Change gated = True for Gated MLP model\n",
    "    \n",
    "    if MODEL_NAME == 'GCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=74; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GraphSage':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=10; hidden_dim=38; out_dim=hidden_dim; dropout=0.0; readout='mean'; layer_type='edgefeat'\n",
    "\n",
    "    if MODEL_NAME == 'GAT':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; n_heads=3; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'; layer_type='dgl'\n",
    "    \n",
    "    if MODEL_NAME == 'GIN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=60; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'MoNet':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=53; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GatedGCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=35; out_dim=hidden_dim; dropout=0.0; readout='mean'; edge_feat = False; layer_type='edgereprfeat'\n",
    "        \n",
    "    # generic new_params\n",
    "    net_params = {}\n",
    "    net_params['device'] = device\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['residual'] = True\n",
    "    net_params['hidden_dim'] = hidden_dim\n",
    "    net_params['out_dim'] = out_dim\n",
    "    num_classes = 1\n",
    "    net_params['n_classes'] = num_classes\n",
    "    net_params['n_heads'] = n_heads\n",
    "    net_params['L'] = L  # min L should be 2\n",
    "    net_params['readout'] = \"mean\"\n",
    "    net_params['layer_norm'] = True\n",
    "    net_params['batch_norm'] = True\n",
    "    net_params['in_feat_dropout'] = 0.0\n",
    "    net_params['dropout'] = 0.0\n",
    "    net_params['edge_feat'] = edge_feat\n",
    "    net_params['self_loop'] = self_loop\n",
    "    net_params['layer_type'] = layer_type\n",
    "    \n",
    "    # for MF\n",
    "    net_params['num_embs'] = num_embs\n",
    "    \n",
    "    # for MLPNet \n",
    "    net_params['gated'] = gated\n",
    "    \n",
    "    # specific for MoNet\n",
    "    net_params['pseudo_dim_MoNet'] = 2\n",
    "    net_params['kernel'] = 3\n",
    "    \n",
    "    # specific for GIN\n",
    "    net_params['n_mlp_GIN'] = 2\n",
    "    net_params['learn_eps_GIN'] = True\n",
    "    net_params['neighbor_aggr_GIN'] = 'sum'\n",
    "    \n",
    "    # specific for graphsage\n",
    "    net_params['sage_aggregator'] = 'maxpool'   \n",
    "    \n",
    "    # specific for pos_enc_dim\n",
    "    net_params['pos_enc'] = pos_enc\n",
    "    net_params['pos_enc_dim'] = pos_enc_dim\n",
    "\n",
    "    \n",
    "    params = {}\n",
    "    params['seed'] = seed\n",
    "    params['epochs'] = epochs\n",
    "    params['batch_size'] = batch_size\n",
    "    params['init_lr'] = init_lr\n",
    "    params['lr_reduce_factor'] = lr_reduce_factor \n",
    "    params['lr_schedule_patience'] = lr_schedule_patience\n",
    "    params['min_lr'] = min_lr\n",
    "    params['weight_decay'] = weight_decay\n",
    "    params['print_epoch_interval'] = 5\n",
    "    params['max_time'] = max_time\n",
    "\n",
    "    return net_params, params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53213f-c54d-47b0-ad7d-48e028d067e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5029223-d582-43a5-a3b8-d84cf8eda6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDF(APPLICATION_NAME):\n",
    "    df = pd.read_csv(\"../new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50becd08-f501-4d82-bc2f-f3316b50fd26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DEFINE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a5e0fb-3c0e-4340-8a2b-4dcbd33f024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_parameter(MODEL_NAME, dataset):\n",
    "    \n",
    "#     MODEL_NAME = 'MF'\n",
    "    # MODEL_NAME = 'GatedGCN'\n",
    "    \n",
    "    n_heads = -1\n",
    "    edge_feat = False\n",
    "    pseudo_dim_MoNet = -1\n",
    "    kernel = -1\n",
    "    gnn_per_block = -1\n",
    "    embedding_dim = -1\n",
    "    pool_ratio = -1\n",
    "    n_mlp_GIN = -1\n",
    "    gated = False\n",
    "    self_loop = False\n",
    "    max_time = 12\n",
    "    layer_type = 'dgl'\n",
    "    num_embs = -1\n",
    "    pos_enc = True\n",
    "    #pos_enc = False\n",
    "    pos_enc_dim = 10\n",
    "\n",
    "    \n",
    "    if MODEL_NAME == 'MF':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.01; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=0; hidden_dim=256; out_dim=hidden_dim; num_embs=235868;\n",
    "    \n",
    "    if MODEL_NAME == 'MLP':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=80; out_dim=hidden_dim; dropout=0.0; readout='mean'; gated = False  # Change gated = True for Gated MLP model\n",
    "    \n",
    "    if MODEL_NAME == 'GCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=74; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GraphSage':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=10; hidden_dim=38; out_dim=hidden_dim; dropout=0.0; readout='mean'; layer_type='edgefeat'\n",
    "\n",
    "    if MODEL_NAME == 'GAT':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; n_heads=3; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'; layer_type='dgl'\n",
    "    \n",
    "    if MODEL_NAME == 'GIN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=60; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'MoNet':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=53; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GatedGCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=35; out_dim=hidden_dim; dropout=0.0; readout='mean'; edge_feat = False; layer_type='edgereprfeat'\n",
    "        \n",
    "    # generic new_params\n",
    "    net_params = {}\n",
    "    net_params['device'] = device\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['residual'] = True\n",
    "    net_params['hidden_dim'] = hidden_dim\n",
    "    net_params['out_dim'] = out_dim\n",
    "    num_classes = 1\n",
    "    net_params['n_classes'] = num_classes\n",
    "    net_params['n_heads'] = n_heads\n",
    "    net_params['L'] = L  # min L should be 2\n",
    "    net_params['readout'] = \"mean\"\n",
    "    net_params['layer_norm'] = True\n",
    "    net_params['batch_norm'] = True\n",
    "    net_params['in_feat_dropout'] = 0.0\n",
    "    net_params['dropout'] = 0.0\n",
    "    net_params['edge_feat'] = edge_feat\n",
    "    net_params['self_loop'] = self_loop\n",
    "    net_params['layer_type'] = layer_type\n",
    "    \n",
    "    # for MF\n",
    "    net_params['num_embs'] = num_embs\n",
    "    \n",
    "    # for MLPNet \n",
    "    net_params['gated'] = gated\n",
    "    \n",
    "    # specific for MoNet\n",
    "    net_params['pseudo_dim_MoNet'] = 2\n",
    "    net_params['kernel'] = 3\n",
    "    \n",
    "    # specific for GIN\n",
    "    net_params['n_mlp_GIN'] = 2\n",
    "    net_params['learn_eps_GIN'] = True\n",
    "    net_params['neighbor_aggr_GIN'] = 'sum'\n",
    "    \n",
    "    # specific for graphsage\n",
    "    net_params['sage_aggregator'] = 'maxpool'   \n",
    "    \n",
    "    # specific for pos_enc_dim\n",
    "    net_params['pos_enc'] = pos_enc\n",
    "    net_params['pos_enc_dim'] = pos_enc_dim\n",
    "\n",
    "    \n",
    "    params = {}\n",
    "    params['seed'] = seed\n",
    "    params['epochs'] = epochs\n",
    "    params['batch_size'] = batch_size\n",
    "    params['init_lr'] = init_lr\n",
    "    params['lr_reduce_factor'] = lr_reduce_factor \n",
    "    params['lr_schedule_patience'] = lr_schedule_patience\n",
    "    params['min_lr'] = min_lr\n",
    "    params['weight_decay'] = weight_decay\n",
    "    params['print_epoch_interval'] = 5\n",
    "    params['max_time'] = max_time\n",
    "\n",
    "    return net_params, params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63646db5-579d-44ef-bc8b-8cd542ede4f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VIEW MODEL PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e9bf1d-0656-4f7e-bcda-43dcbb0bd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def view_model_param(MODEL_NAME, net_params):\n",
    "    # print(net_params)\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    total_param = 0\n",
    "    # print(\"MODEL DETAILS:\\n\")\n",
    "    # print(model)\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    # print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
    "    return total_param\n",
    "\n",
    "tim1 = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575f6ac-30e4-468e-9e9b-8a3b223d8d74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138ae866-694c-4f97-af6d-8acb59e1c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(MODEL_NAME, dataset, DATASET_NAME):\n",
    "    net_params, params = define_parameter(MODEL_NAME=MODEL_NAME, dataset=dataset)\n",
    "    config = {}\n",
    "    gpu = {}\n",
    "    gpu['use'] = use_gpu\n",
    "    gpu['id'] = gpu_id\n",
    "    config['gpu'] = gpu\n",
    "    # GNN model, dataset, out_dir\n",
    "    config['model'] = MODEL_NAME\n",
    "    config['dataset'] = DATASET_NAME\n",
    "    out_dir = 'out/debug/'\n",
    "    config['out_dir'] = out_dir\n",
    "    config['params'] = params\n",
    "    # network parameters\n",
    "    config['net_params'] = net_params\n",
    "    params = config['params']\n",
    "    DATASET_NAME = config['dataset']\n",
    "    device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
    "    out_dir = config['out_dir']\n",
    "    MODEL_NAME = config['model']\n",
    "    net_params = config['net_params']\n",
    "    net_params['device'] = device\n",
    "    net_params['gpu_id'] = config['gpu']['id']\n",
    "    net_params['batch_size'] = params['batch_size']\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['n_classes'] = 1  # binary prediction\n",
    "    net_params['total_param'] = view_model_param(MODEL_NAME, net_params)\n",
    "    \n",
    "    return net_params, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b05bab-c105-42f7-aee4-f18a0a5ddc21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get Epoc Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c00d9ba4-9be4-4cea-a244-002e2226c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EPOC_Number(PATH):\n",
    "    file_path = PATH+\"/ROC_CURVE/*\"\n",
    "    project_list = glob.glob(file_path)\n",
    "    max_ = -1\n",
    "    for line in project_list:\n",
    "        index = line.rfind(\"_\")\n",
    "        last_index = line.rfind(\".png\")\n",
    "        number = int(line[index+1:last_index])\n",
    "        max_ = max(max_, number)\n",
    "    # print(max_)\n",
    "    return max_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c64d3-2798-4b63-a43a-b7aa5166e718",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85500d9-3bf9-4e71-b4b7-9464339fbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME):\n",
    "    t0 = time.time()    \n",
    "    DATASET_NAME = dataset.name\n",
    "\n",
    "    if MODEL_NAME in ['GatedGCN']:\n",
    "        if net_params['pos_enc']:\n",
    "            print(\"[!] Adding graph positional encoding\",net_params['pos_enc_dim'])\n",
    "            dataset._add_positional_encodings(net_params['pos_enc_dim'])\n",
    "            print('Time PE:',time.time()-t0)\n",
    "\n",
    "    graph = dataset.graph\n",
    "    evaluator=\"\"\n",
    "    train_edges, val_edges, val_edges_neg, test_edges, test_edges_neg = dataset.train_edges, dataset.val_edges, dataset.val_edges_neg, dataset.test_edges, dataset.test_edges_neg\n",
    "    device = net_params['device']\n",
    "    random.seed(params['seed'])\n",
    "    np.random.seed(params['seed'])\n",
    "    torch.manual_seed(params['seed'])\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(params['seed'])\n",
    "\n",
    "    print(\"Graph: \", graph)\n",
    "    print(\"Training Edges: \", len(train_edges))\n",
    "    print(\"Validation Edges: \", len(val_edges) + len(val_edges_neg))\n",
    "    print(\"Test Edges: \", len(test_edges) + len(test_edges_neg))\n",
    "\n",
    "    print(net_params)\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    model = model.to(device)\n",
    "    out_dir = 'out/debug/'\n",
    "    PATH = out_dir + 'checkpoints/' + MODEL_NAME + \"_NEW_DATASET--\" + APPLICATION_NAME + \"/RUN_/epoch_\"+str(EPOC_NUMBER)+\".pkl\"\n",
    "    t = torch.load(PATH)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "#     print(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                        factor=params['lr_reduce_factor'],\n",
    "                                                        patience=params['lr_schedule_patience'],\n",
    "                                                        verbose=True)\n",
    "\n",
    "    return model, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603a19f-80fb-4fcc-86ba-577034030c93",
   "metadata": {},
   "source": [
    "## Get Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f4109f-9d3e-4f99-9d13-d83941474b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(test_size, APPLICATION_NAME=\"\"):\n",
    "    ROOT_PATH = \"../new/\"\n",
    "    df = pd.read_csv(ROOT_PATH+ APPLICATION_NAME+'_node.csv')\n",
    "    nodes_data = df.drop([\"start_line\",\"start_column\",\"end_line\",  \"end_column\" ,\"file_name\"], axis=1)\n",
    "    \n",
    "    stmt_type=['FunctionDeclaration', 'ArrowFunctionExpression', 'FunctionExpression']\n",
    "    df1 = nodes_data[nodes_data.type.isin(stmt_type)]\n",
    "    test_neg_id = df1['new_id'].tolist()\n",
    "\n",
    "    df1 = nodes_data[((nodes_data['type']=='CallExpression')|(nodes_data['type']=='NewExpression'))]\n",
    "    test_neg_call_site = df1['new_id'].tolist()\n",
    "\n",
    "    test_edges= pd.read_csv(ROOT_PATH+ APPLICATION_NAME +'_function_edges.csv')\n",
    "\n",
    "    test_edges.columns = [\"src\", \"dst\"]\n",
    "    index = pd.MultiIndex.from_product([test_neg_call_site, test_neg_id], names = [\"src\", \"dst\"])\n",
    "    all_combi = pd.DataFrame(index = index).reset_index()\n",
    "    \n",
    "    test_neg_df =  pd.merge(all_combi,test_edges, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "    test_neg_df = test_neg_df.iloc[np.random.permutation(len(test_neg_df))]\n",
    "    # print(test_neg_df)\n",
    "    test_neg_df = test_neg_df[:test_size]\n",
    "    test_edges = torch.from_numpy(test_neg_df.to_numpy())\n",
    "    return test_edges\n",
    "#     return test_neg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead695f-7767-484f-9c14-0ad3eea8da0d",
   "metadata": {},
   "source": [
    "## Get Cutoff Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a3829a-a3e1-42e3-9966-7a52b4f6e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds(PATH, EPOC_NUMBER):\n",
    "    all_list =[[],[],[]]\n",
    "    k=0\n",
    "    with open(PATH+\"/THRESHOLD/threshold_values_with_\"+str(EPOC_NUMBER)+\".txt\") as in_file:\n",
    "        for line in in_file:\n",
    "            parts = line.split(\" \")\n",
    "            # print(parts)\n",
    "            for part in parts:\n",
    "                try:\n",
    "                    numeric_string = float(''.join(c for c in part if (c.isdigit() or c =='.' or c=='e' or c=='-')))\n",
    "                    # print(numeric_string)\n",
    "                    all_list[k].append(numeric_string)\n",
    "                except:\n",
    "                    pass\n",
    "            if \"]\" in line:\n",
    "                k+=1\n",
    "\n",
    "    threshold_lst = all_list[0]\n",
    "    fpr_lst = all_list[1]\n",
    "    tpr_lst = all_list[2]\n",
    "\n",
    "    # print(threshold_lst)\n",
    "    for i in range(len(fpr_lst)):\n",
    "        if fpr_lst[i]!=0.0:\n",
    "            first_index = i-1\n",
    "            break\n",
    "    \n",
    "\n",
    "    first_thrshld = threshold_lst[first_index]\n",
    "\n",
    "    return first_thrshld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bb381c-96a8-475b-bbce-1bd992e327f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION_NAME = 'express'\n",
    "# PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "# EPOC_NUMBER = get_EPOC_Number(PATH=PATH)\n",
    "# print(EPOC_NUMBER)\n",
    "# print(get_thresholds(PATH=PATH, EPOC_NUMBER=EPOC_NUMBER))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95c2ee-8969-4cf0-973b-d6b44c67cb17",
   "metadata": {},
   "source": [
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce974b5-3310-4702-8340-bb5e4999d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_network(model, device, graph, test_edges,\n",
    "                     batch_size, DATASET_NAME=\"\", MODEL_NAME=\"\", SOURCE_NODE=0, DST_NODE=0, APPLICATION_NAME=\"\", EPOC_NUMBER=0):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph = graph.to(device)\n",
    "        x = graph.ndata['feat'].to(device)\n",
    "        e = graph.edata['feat'].to(device).float()\n",
    "        try:\n",
    "            x_pos_enc = graph.ndata['pos_enc'].to(device)\n",
    "            h = model(graph, x, e, x_pos_enc) \n",
    "        except:\n",
    "            h = model(graph, x, e)\n",
    "\n",
    "        test_edges = test_edges.to(device)\n",
    "\n",
    "        test_preds = []\n",
    "        for perm in DataLoader(range(test_edges.size(0)), batch_size):\n",
    "            edge = test_edges[perm].t()\n",
    "            # print(\"edge ==> \",edge, len(edge))\n",
    "            test_preds += [model.edge_predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "        # print(test_preds)\n",
    "        if len(test_edges)==1:\n",
    "            t= test_preds[0]\n",
    "            t =np.expand_dims(t,0)\n",
    "            t = torch.tensor(t)\n",
    "            test_preds = [t]\n",
    "        test_pred = torch.cat(test_preds, dim=0)\n",
    "        print(test_pred)\n",
    "        \n",
    "    cutoff_thrshld = get_thresholds(PATH=PATH, EPOC_NUMBER=EPOC_NUMBER)\n",
    "    cutoff_thrshld = \"{:.12f}\".format(float(cutoff_thrshld))\n",
    "    count = 0\n",
    "    for i in range(len(test_pred)):\n",
    "        pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "        if(pred_score >= cutoff_thrshld):\n",
    "           count+=1\n",
    "    \n",
    "    print(count)\n",
    "        \n",
    "#     write_to_file(test_edges=test_edges, test_pred=test_pred, src_id=SOURCE_NODE, APPLICATION_NAME=APPLICATION_NAME)\n",
    "\n",
    "#     src=[]\n",
    "#     dst=[]\n",
    "#     scores = []\n",
    "#     for i in range(len(test_edges)):\n",
    "#         pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "#         s = int(test_edges[i][0].item())\n",
    "#         d = int(test_edges[i][1].item())\n",
    "#         src.append(s)\n",
    "#         dst.append(d)\n",
    "#         scores.append(pred_score)\n",
    "\n",
    "#     d = {\"src\": src, \"dst\":dst, \"score\":scores}\n",
    "#     df = pd.DataFrame(d)\n",
    "#     df = df.sort_values(by='score', ascending=False, na_position='first').reset_index(drop=True)\n",
    "#     temp_df = df[(df[\"src\"]==SOURCE_NODE) & (df[\"dst\"]== DST_NODE)]\n",
    "#     if len(temp_df)!=0:\n",
    "#         print(\"ACTUAL EDGE RANK =====> \", temp_df.index[0])\n",
    "#         return temp_df.index[0]\n",
    "#     else:\n",
    "#         print(SOURCE_NODE, DST_NODE)\n",
    "#         print(df)\n",
    "#     return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75fa61f-7f2a-4930-b1dd-ed2e87228a4b",
   "metadata": {},
   "source": [
    "## Get Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f29bde-c91d-46cf-b2f5-4dbf4d39be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME):\n",
    "    \n",
    "#     for i in range(len(pos_df)):\n",
    "#         src_id = int(pos_df.iloc[i][0])\n",
    "#         dst_id = int(pos_df.iloc[i][1])\n",
    "# #         print(src_id, dst_id)\n",
    "#         try:\n",
    "#             start = time.time()\n",
    "#             test_edges = get_test_data(test_size=10000, APPLICATION_NAME=APPLICATION_NAME)\n",
    "# #             # print(len(test_edges), src_id, dst_id)\n",
    "# #             if len(test_edges) > 0:\n",
    "# #                 rank = evaluate_network(\n",
    "# #                         model, device, graph, test_edges, params['batch_size'], DATASET_NAME=DATASET_NAME, MODEL_NAME=MODEL_NAME, SOURCE_NODE=src_id, DST_NODE=dst_id, APPLICATION_NAME=APPLICATION_NAME)\n",
    "# #             # if src_name == dst_name:\n",
    "# #                 if rank!= -1:\n",
    "# #                     if rank<=5:\n",
    "# #                     # print(rank)\n",
    "# #                         count+=1\n",
    "# #                     else:\n",
    "# #                         not_top+=1\n",
    "# #                 else:\n",
    "# #                     print(\"PROBLEM!!!\")\n",
    "# #                 rank_list.append(rank)\n",
    "#         except KeyboardInterrupt:\n",
    "#             print('-' * 89)\n",
    "#             print('Exiting from training early because of KeyboardInterrupt')\n",
    "\n",
    "# #                 # break\n",
    "\n",
    "# #     return rank_list\n",
    "\n",
    "\n",
    "    test_edges = get_test_data(test_size=10000, APPLICATION_NAME=APPLICATION_NAME)\n",
    "    evaluate_network(model, device, graph, test_edges, params['batch_size'], DATASET_NAME=DATASET_NAME, MODEL_NAME=MODEL_NAME, APPLICATION_NAME=APPLICATION_NAME, EPOC_NUMBER=EPOC_NUMBER)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6149ab-e4f4-4173-857b-eacee49665bb",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc15424-cd6b-4ba0-83df-8e4e43092d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'GatedGCN'\n",
    "# to_do_list = ['js-data', 'atropa-ide', 'mathjs','mixin-pro', 'locutus', 'is-my-json-valid', 'ms' ]\n",
    "# app_list = ['js-data_3.0.9', 'atropa-ide_0.2.2-2', 'mathjs_3.9.0','mixin-pro_0.6.0', 'locutus_2.0.10', 'is-my-json-valid_2.20.0', 'ms_0.7.0']\n",
    "\n",
    "# to_do_list = ['lodash', 'formula-parser', 'mathjs' ]\n",
    "# app_list = ['lodash', 'formula-parser', 'mathjs' ]\n",
    "\n",
    "to_do_list = ['formula-parser', 'lodash', 'express','js-yaml']\n",
    "app_list =  ['formula-parser', 'lodash', 'express','js-yaml']\n",
    "\n",
    "# to_do_list = ['is-my-json-valid']\n",
    "# app_list = ['is-my-json-valid_2.20.0']\n",
    "\n",
    "print(os.getcwd())\n",
    "if \"with_dynamic_edge\" not in str(os.getcwd()):\n",
    "    os.chdir('with_dynamic_edge/')\n",
    "print(os.getcwd())\n",
    "for i in range(len(to_do_list)):\n",
    "    APPLICATION_NAME = app_list[i]\n",
    "    DATASET_NAME = 'NEW_DATASET--'+APPLICATION_NAME\n",
    "    print(\"\\033[97m ------------------------------------------------------------------\")\n",
    "    print(\"\\033[97m \", APPLICATION_NAME)\n",
    "    print(\"\\033[97m ------------------------------------------------------------------\")\n",
    "    # print(\"[I] Loading data (notebook) ...\")\n",
    "    node_df = LoadDF(APPLICATION_NAME)\n",
    "    # print(node_df)\n",
    "    # print(\"[I] Finished loading.\")\n",
    "    PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "    EPOC_NUMBER = get_EPOC_Number(PATH=PATH)\n",
    "    print(EPOC_NUMBER)\n",
    "    dataset = load_datset(DATASET_NAME)\n",
    "    net_params, params = set_parameters(MODEL_NAME, dataset, DATASET_NAME)\n",
    "    model, graph = train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME)\n",
    "    # print(model, graph)\n",
    "    rank_list = get_candidate(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME)\n",
    "#     plot_graph(rank_list, APPLICATION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "930c64ea-bdbb-4688-b71a-3c0cacdc45c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lodash', 'underscore', 'eslint-plugin-import', 'mocha', 'angular', 'ramda', 'shelljs', 'js-yaml', 'commander.js', 'bluebird', 'express', 'async', 'jsPDF', 'jquery', 'coffeescript', 'handlebars.js', 'bootstrap', 'immutable-js', 'package', 'q', 'formula-parser', 'atompm', 'request', 'mongoose', 'mathjs', 'less.js', 'webpack', 'eslint-plugin-react', 'axios', 'react']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "folders = glob.glob(\"../prune_new/*\")\n",
    "project_list = ['moment', 'jsPDF', 'webpack', 'atompm', 'jquery', 'ws', 'cheerio', 'yargs', 'eslint-plugin-react', 'socket.io', 'sass-loader', 'handlebars.js']\n",
    "count = 0\n",
    "lst=[]\n",
    "# for file_ in folders:\n",
    "#     first_index = file_.rfind(\"/\")\n",
    "#     last_index = file_.rfind(\"_function_edges.csv\")\n",
    "#     DATASET_NAME = file_[first_index+1:last_index]\n",
    "#     if \"function_edges.csv\" in file_:\n",
    "#         df =pd.read_csv(file_)\n",
    "#         if DATASET_NAME in project_list and len(df)>500:\n",
    "#             print(DATASET_NAME,\"=======>\",len(df))\n",
    "#             lst.append(DATASET_NAME)\n",
    "#             count+=1\n",
    "\n",
    "# print(lst)\n",
    "\n",
    "# for file_ in folders:\n",
    "#     first_index = file_.rfind(\"/\")\n",
    "#     last_index = file_.rfind(\"_node\")\n",
    "#     DATASET_NAME = file_[first_index+1:last_index]\n",
    "#     if \"_node\" in file_:\n",
    "#         df =pd.read_csv(file_)\n",
    "#         if DATASET_NAME in project_list and len(df)>500:\n",
    "#             print(DATASET_NAME,\"=======>\",len(df))\n",
    "#             lst.append(DATASET_NAME)\n",
    "#             count+=1\n",
    "\n",
    "# print(lst)\n",
    "from os.path import exists\n",
    "count = 0\n",
    "lst = []\n",
    "folders = glob.glob(\"results/*\")\n",
    "for folder_path in folders:\n",
    "    first_index = folder_path.rfind(\"--\")\n",
    "    DATASET_NAME = folder_path[first_index+2:]\n",
    "    file_exists = exists(folder_path+\"/GatedGCN/train_loss.png\")\n",
    "    if file_exists:\n",
    "        df = pd.read_csv(folder_path+\"/GatedGCN/POS_PRED/pred_score_with_0_pos.csv\", header=None)\n",
    "        if len(df)>50:\n",
    "            # print(DATASET_NAME, \"======> \",len(df))\n",
    "            lst.append(DATASET_NAME) \n",
    "# print(count)\n",
    "print(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
