{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ca17c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc5210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "# os.chdir('../')\n",
    "# print(os.getcwd())\n",
    "# if \"experimental_copy_redo\" in str(os.getcwd()):\n",
    "#     os.chdir('../')\n",
    "\"\"\"\n",
    "    IMPORTING LIBS\n",
    "\"\"\"\n",
    "import dgl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import argparse, json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dgl.function as fn\n",
    "MODEL_NAME = 'GraphSage'\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "\"\"\"\n",
    "    IMPORTING CUSTOM MODULES/METHODS\n",
    "\"\"\"\n",
    "# from nets.COLLAB_edge_classification.load_net import gnn_model # import all GNNS\n",
    "from nets.COLLAB_edge_classification.load_net import gnn_model\n",
    "from data.data import LoadData\n",
    "\"\"\"\n",
    "    GPU Setup\n",
    "\"\"\"\n",
    "def gpu_setup(use_gpu, gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "#         print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "#         print('cuda not available')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "use_gpu = False; gpu_id = -1; device = None # CPU\n",
    "# \"\"\"\n",
    "#     USER CONTROLS\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffe28c-9432-49d8-ad5b-40013c3f41de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "842a3e7a-16a3-4cfb-8e1e-4f704ad8381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datset(DATASET_NAME):\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    print(\"[I] Finished loading.....\")\n",
    "    # print(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75672b-cd34-4ddb-baca-63d14825afd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DEFINE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6552916-1712-4568-826f-cd47839a34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_parameter(MODEL_NAME, dataset):\n",
    "    \n",
    "#     MODEL_NAME = 'MF'\n",
    "    # MODEL_NAME = 'GatedGCN'\n",
    "    \n",
    "    n_heads = -1\n",
    "    edge_feat = False\n",
    "    pseudo_dim_MoNet = -1\n",
    "    kernel = -1\n",
    "    gnn_per_block = -1\n",
    "    embedding_dim = -1\n",
    "    pool_ratio = -1\n",
    "    n_mlp_GIN = -1\n",
    "    gated = False\n",
    "    self_loop = False\n",
    "    max_time = 12\n",
    "    layer_type = 'dgl'\n",
    "    num_embs = -1\n",
    "    pos_enc = True\n",
    "    #pos_enc = False\n",
    "    pos_enc_dim = 10\n",
    "\n",
    "    \n",
    "    if MODEL_NAME == 'MF':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.01; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=0; hidden_dim=256; out_dim=hidden_dim; num_embs=235868;\n",
    "    \n",
    "    if MODEL_NAME == 'MLP':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=80; out_dim=hidden_dim; dropout=0.0; readout='mean'; gated = False  # Change gated = True for Gated MLP model\n",
    "    \n",
    "    if MODEL_NAME == 'GCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=74; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GraphSage':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=10; hidden_dim=38; out_dim=hidden_dim; dropout=0.0; readout='mean'; layer_type='edgefeat'\n",
    "\n",
    "    if MODEL_NAME == 'GAT':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; n_heads=3; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'; layer_type='dgl'\n",
    "    \n",
    "    if MODEL_NAME == 'GIN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=60; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'MoNet':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=53; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GatedGCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=35; out_dim=hidden_dim; dropout=0.0; readout='mean'; edge_feat = False; layer_type='edgereprfeat'\n",
    "        \n",
    "    # generic new_params\n",
    "    net_params = {}\n",
    "    net_params['device'] = device\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['residual'] = True\n",
    "    net_params['hidden_dim'] = hidden_dim\n",
    "    net_params['out_dim'] = out_dim\n",
    "    num_classes = 1\n",
    "    net_params['n_classes'] = num_classes\n",
    "    net_params['n_heads'] = n_heads\n",
    "    net_params['L'] = L  # min L should be 2\n",
    "    net_params['readout'] = \"mean\"\n",
    "    net_params['layer_norm'] = True\n",
    "    net_params['batch_norm'] = True\n",
    "    net_params['in_feat_dropout'] = 0.0\n",
    "    net_params['dropout'] = 0.0\n",
    "    net_params['edge_feat'] = edge_feat\n",
    "    net_params['self_loop'] = self_loop\n",
    "    net_params['layer_type'] = layer_type\n",
    "    \n",
    "    # for MF\n",
    "    net_params['num_embs'] = num_embs\n",
    "    \n",
    "    # for MLPNet \n",
    "    net_params['gated'] = gated\n",
    "    \n",
    "    # specific for MoNet\n",
    "    net_params['pseudo_dim_MoNet'] = 2\n",
    "    net_params['kernel'] = 3\n",
    "    \n",
    "    # specific for GIN\n",
    "    net_params['n_mlp_GIN'] = 2\n",
    "    net_params['learn_eps_GIN'] = True\n",
    "    net_params['neighbor_aggr_GIN'] = 'sum'\n",
    "    \n",
    "    # specific for graphsage\n",
    "    net_params['sage_aggregator'] = 'maxpool'   \n",
    "    \n",
    "    # specific for pos_enc_dim\n",
    "    net_params['pos_enc'] = pos_enc\n",
    "    net_params['pos_enc_dim'] = pos_enc_dim\n",
    "\n",
    "    \n",
    "    params = {}\n",
    "    params['seed'] = seed\n",
    "    params['epochs'] = epochs\n",
    "    params['batch_size'] = batch_size\n",
    "    params['init_lr'] = init_lr\n",
    "    params['lr_reduce_factor'] = lr_reduce_factor \n",
    "    params['lr_schedule_patience'] = lr_schedule_patience\n",
    "    params['min_lr'] = min_lr\n",
    "    params['weight_decay'] = weight_decay\n",
    "    params['print_epoch_interval'] = 5\n",
    "    params['max_time'] = max_time\n",
    "\n",
    "    return net_params, params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53213f-c54d-47b0-ad7d-48e028d067e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5029223-d582-43a5-a3b8-d84cf8eda6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDF(APPLICATION_NAME):\n",
    "    df = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50becd08-f501-4d82-bc2f-f3316b50fd26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DEFINE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a5e0fb-3c0e-4340-8a2b-4dcbd33f024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_parameter(MODEL_NAME, dataset):\n",
    "    \n",
    "#     MODEL_NAME = 'MF'\n",
    "    # MODEL_NAME = 'GatedGCN'\n",
    "    \n",
    "    n_heads = -1\n",
    "    edge_feat = False\n",
    "    pseudo_dim_MoNet = -1\n",
    "    kernel = -1\n",
    "    gnn_per_block = -1\n",
    "    embedding_dim = -1\n",
    "    pool_ratio = -1\n",
    "    n_mlp_GIN = -1\n",
    "    gated = False\n",
    "    self_loop = False\n",
    "    max_time = 12\n",
    "    layer_type = 'dgl'\n",
    "    num_embs = -1\n",
    "    pos_enc = True\n",
    "    #pos_enc = False\n",
    "    pos_enc_dim = 10\n",
    "\n",
    "    \n",
    "    if MODEL_NAME == 'MF':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.01; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=0; hidden_dim=256; out_dim=hidden_dim; num_embs=235868;\n",
    "    \n",
    "    if MODEL_NAME == 'MLP':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=80; out_dim=hidden_dim; dropout=0.0; readout='mean'; gated = False  # Change gated = True for Gated MLP model\n",
    "    \n",
    "    if MODEL_NAME == 'GCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=74; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GraphSage':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=10; hidden_dim=38; out_dim=hidden_dim; dropout=0.0; readout='mean'; layer_type='edgefeat'\n",
    "\n",
    "    if MODEL_NAME == 'GAT':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; n_heads=3; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'; layer_type='dgl'\n",
    "    \n",
    "    if MODEL_NAME == 'GIN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=60; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'MoNet':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=3; hidden_dim=53; out_dim=hidden_dim; dropout=0.0; readout='mean';\n",
    "        \n",
    "    if MODEL_NAME == 'GatedGCN':\n",
    "        seed=41; epochs=500; batch_size=32*1024; init_lr=0.001; lr_reduce_factor=0.5; lr_schedule_patience=10; min_lr = 1e-5; weight_decay=0\n",
    "        L=5; hidden_dim=35; out_dim=hidden_dim; dropout=0.0; readout='mean'; edge_feat = False; layer_type='edgereprfeat'\n",
    "        \n",
    "    # generic new_params\n",
    "    net_params = {}\n",
    "    net_params['device'] = device\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['residual'] = True\n",
    "    net_params['hidden_dim'] = hidden_dim\n",
    "    net_params['out_dim'] = out_dim\n",
    "    num_classes = 1\n",
    "    net_params['n_classes'] = num_classes\n",
    "    net_params['n_heads'] = n_heads\n",
    "    net_params['L'] = L  # min L should be 2\n",
    "    net_params['readout'] = \"mean\"\n",
    "    net_params['layer_norm'] = True\n",
    "    net_params['batch_norm'] = True\n",
    "    net_params['in_feat_dropout'] = 0.0\n",
    "    net_params['dropout'] = 0.0\n",
    "    net_params['edge_feat'] = edge_feat\n",
    "    net_params['self_loop'] = self_loop\n",
    "    net_params['layer_type'] = layer_type\n",
    "    \n",
    "    # for MF\n",
    "    net_params['num_embs'] = num_embs\n",
    "    \n",
    "    # for MLPNet \n",
    "    net_params['gated'] = gated\n",
    "    \n",
    "    # specific for MoNet\n",
    "    net_params['pseudo_dim_MoNet'] = 2\n",
    "    net_params['kernel'] = 3\n",
    "    \n",
    "    # specific for GIN\n",
    "    net_params['n_mlp_GIN'] = 2\n",
    "    net_params['learn_eps_GIN'] = True\n",
    "    net_params['neighbor_aggr_GIN'] = 'sum'\n",
    "    \n",
    "    # specific for graphsage\n",
    "    net_params['sage_aggregator'] = 'maxpool'   \n",
    "    \n",
    "    # specific for pos_enc_dim\n",
    "    net_params['pos_enc'] = pos_enc\n",
    "    net_params['pos_enc_dim'] = pos_enc_dim\n",
    "\n",
    "    \n",
    "    params = {}\n",
    "    params['seed'] = seed\n",
    "    params['epochs'] = epochs\n",
    "    params['batch_size'] = batch_size\n",
    "    params['init_lr'] = init_lr\n",
    "    params['lr_reduce_factor'] = lr_reduce_factor \n",
    "    params['lr_schedule_patience'] = lr_schedule_patience\n",
    "    params['min_lr'] = min_lr\n",
    "    params['weight_decay'] = weight_decay\n",
    "    params['print_epoch_interval'] = 5\n",
    "    params['max_time'] = max_time\n",
    "\n",
    "    return net_params, params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63646db5-579d-44ef-bc8b-8cd542ede4f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VIEW MODEL PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3e9bf1d-0656-4f7e-bcda-43dcbb0bd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def view_model_param(MODEL_NAME, net_params):\n",
    "    # print(net_params)\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    total_param = 0\n",
    "    # print(\"MODEL DETAILS:\\n\")\n",
    "    # print(model)\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    # print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
    "    return total_param\n",
    "\n",
    "tim1 = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575f6ac-30e4-468e-9e9b-8a3b223d8d74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "138ae866-694c-4f97-af6d-8acb59e1c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(MODEL_NAME, dataset, DATASET_NAME):\n",
    "    net_params, params = define_parameter(MODEL_NAME=MODEL_NAME, dataset=dataset)\n",
    "    config = {}\n",
    "    gpu = {}\n",
    "    gpu['use'] = use_gpu\n",
    "    gpu['id'] = gpu_id\n",
    "    config['gpu'] = gpu\n",
    "    # GNN model, dataset, out_dir\n",
    "    config['model'] = MODEL_NAME\n",
    "    config['dataset'] = DATASET_NAME\n",
    "    out_dir = 'out/debug/'\n",
    "    config['out_dir'] = out_dir\n",
    "    config['params'] = params\n",
    "    # network parameters\n",
    "    config['net_params'] = net_params\n",
    "    params = config['params']\n",
    "    DATASET_NAME = config['dataset']\n",
    "    device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
    "    out_dir = config['out_dir']\n",
    "    MODEL_NAME = config['model']\n",
    "    net_params = config['net_params']\n",
    "    net_params['device'] = device\n",
    "    net_params['gpu_id'] = config['gpu']['id']\n",
    "    net_params['batch_size'] = params['batch_size']\n",
    "    net_params['in_dim'] = dataset.graph.ndata['feat'].shape[-1]\n",
    "    net_params['in_dim_edge'] = dataset.graph.edata['feat'].shape[-1]\n",
    "    net_params['n_classes'] = 1  # binary prediction\n",
    "    net_params['total_param'] = view_model_param(MODEL_NAME, net_params)\n",
    "    \n",
    "    return net_params, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b05bab-c105-42f7-aee4-f18a0a5ddc21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get Epoc Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00d9ba4-9be4-4cea-a244-002e2226c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EPOC_Number(PATH):\n",
    "    file_path = PATH+\"/ROC_CURVE/*\"\n",
    "    project_list = glob.glob(file_path)\n",
    "    max_ = -1\n",
    "    for line in project_list:\n",
    "        index = line.rfind(\"_\")\n",
    "        last_index = line.rfind(\".png\")\n",
    "        number = int(line[index+1:last_index])\n",
    "        max_ = max(max_, number)\n",
    "    # print(max_)\n",
    "    return max_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c64d3-2798-4b63-a43a-b7aa5166e718",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f85500d9-3bf9-4e71-b4b7-9464339fbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME):\n",
    "    t0 = time.time()    \n",
    "    DATASET_NAME = dataset.name\n",
    "\n",
    "    if MODEL_NAME in ['GatedGCN']:\n",
    "        if net_params['pos_enc']:\n",
    "#             print(\"[!] Adding graph positional encoding\",net_params['pos_enc_dim'])\n",
    "            dataset._add_positional_encodings(net_params['pos_enc_dim'])\n",
    "#             print('Time PE:',time.time()-t0)\n",
    "\n",
    "    graph = dataset.graph\n",
    "    evaluator=\"\"\n",
    "    train_edges, val_edges, val_edges_neg, test_edges, test_edges_neg = dataset.train_edges, dataset.val_edges, dataset.val_edges_neg, dataset.test_edges, dataset.test_edges_neg\n",
    "    device = net_params['device']\n",
    "    random.seed(params['seed'])\n",
    "    np.random.seed(params['seed'])\n",
    "    torch.manual_seed(params['seed'])\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(params['seed'])\n",
    "\n",
    "#     print(\"Graph: \", graph)\n",
    "#     print(\"Training Edges: \", len(train_edges))\n",
    "#     print(\"Validation Edges: \", len(val_edges) + len(val_edges_neg))\n",
    "#     print(\"Test Edges: \", len(test_edges) + len(test_edges_neg))\n",
    "\n",
    "#     print(net_params)\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    model = model.to(device)\n",
    "    out_dir = 'out/debug/'\n",
    "    PATH = out_dir + 'checkpoints/' + MODEL_NAME + \"_NEW_DATASET--\" + APPLICATION_NAME + \"/RUN_/epoch_\"+str(EPOC_NUMBER)+\".pkl\"\n",
    "    t = torch.load(PATH)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "#     print(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                        factor=params['lr_reduce_factor'],\n",
    "                                                        patience=params['lr_schedule_patience'],\n",
    "                                                        verbose=True)\n",
    "\n",
    "    return model, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603a19f-80fb-4fcc-86ba-577034030c93",
   "metadata": {},
   "source": [
    "## Get Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6248308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_test_data(src_id,test_size, APPLICATION_NAME=\"\"):\n",
    "    ROOT_PATH = \"../prune_new/\"\n",
    "    df = pd.read_csv(ROOT_PATH+ APPLICATION_NAME+'_node.csv')\n",
    "    nodes_data = df.drop([\"start_line\",\"start_column\",\"end_line\",  \"end_column\" ,\"file_name\"], axis=1)\n",
    "    \n",
    "    stmt_type=['FunctionDeclaration', 'ArrowFunctionExpression', 'FunctionExpression']\n",
    "    df1 = nodes_data[nodes_data.type.isin(stmt_type)]\n",
    "    test_neg_id = df1['new_id'].tolist()\n",
    "\n",
    "    df1 = nodes_data[((nodes_data['type']=='CallExpression')|(nodes_data['type']=='NewExpression'))]\n",
    "    test_neg_call_site = df1['new_id'].tolist()\n",
    "\n",
    "    test_edges= pd.read_csv(ROOT_PATH+ APPLICATION_NAME +'_function_edges.csv')\n",
    "\n",
    "    test_edges.columns = [\"src\", \"dst\"]\n",
    "    index = pd.MultiIndex.from_product([test_neg_call_site, test_neg_id], names = [\"src\", \"dst\"])\n",
    "    all_combi = pd.DataFrame(index = index).reset_index()\n",
    "    \n",
    "    test_neg_df =  pd.merge(all_combi,test_edges, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "    test_neg_df = test_neg_df.iloc[np.random.permutation(len(test_neg_df))]\n",
    "    test_neg_df = test_neg_df[test_neg_df['src']==src_id]\n",
    "    test_neg_df = test_neg_df[:test_size]\n",
    "    test_edges = torch.from_numpy(test_neg_df.to_numpy())\n",
    "    return test_edges\n",
    "#     return test_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69f4109f-9d3e-4f99-9d13-d83941474b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(file_name, src_id, APPLICATION_NAME):\n",
    "    # print(src_id)\n",
    "    f = open('candidate_edge_files/'+APPLICATION_NAME+'_candidate_edges.json')\n",
    "    data = json.load(f)\n",
    "    u=[]\n",
    "    v=[]\n",
    "    test_neg_id = data[file_name]\n",
    "    done_list={}\n",
    "    for node in test_neg_id:\n",
    "        if (src_id,node) not in done_list:\n",
    "                u.append(src_id)\n",
    "                v.append(node)\n",
    "                done_list[(src_id,node)]=True\n",
    "\n",
    "    d={'src':u, 'dst':v}\n",
    "    test_df = pd.DataFrame(d)\n",
    "    test_edges = torch.from_numpy(test_df.to_numpy())\n",
    "    random_test_edge={}\n",
    "    return test_edges, random_test_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead695f-7767-484f-9c14-0ad3eea8da0d",
   "metadata": {},
   "source": [
    "## Get Cutoff Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90a3829a-a3e1-42e3-9966-7a52b4f6e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds(PATH, EPOC_NUMBER):\n",
    "    all_list =[[],[],[]]\n",
    "    k=0\n",
    "    with open(PATH+\"/THRESHOLD/threshold_values_with_\"+str(EPOC_NUMBER)+\".txt\") as in_file:\n",
    "        for line in in_file:\n",
    "            parts = line.split(\" \")\n",
    "            # print(parts)\n",
    "            for part in parts:\n",
    "                try:\n",
    "                    numeric_string = float(''.join(c for c in part if (c.isdigit() or c =='.' or c=='e' or c=='-')))\n",
    "                    # print(numeric_string)\n",
    "                    all_list[k].append(numeric_string)\n",
    "                except:\n",
    "                    pass\n",
    "            if \"]\" in line:\n",
    "                k+=1\n",
    "\n",
    "    threshold_lst = all_list[0]\n",
    "    fpr_lst = all_list[1]\n",
    "    tpr_lst = all_list[2]\n",
    "\n",
    "    # print(threshold_lst)\n",
    "    for i in range(len(fpr_lst)):\n",
    "        if fpr_lst[i]>=0.05:\n",
    "            first_index = i-1\n",
    "            break\n",
    "    \n",
    "    # print(first_index)\n",
    "    first_thrshld = threshold_lst[first_index]\n",
    "\n",
    "    return first_thrshld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13bb381c-96a8-475b-bbce-1bd992e327f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION_NAME = 'express'\n",
    "# PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "# EPOC_NUMBER = get_EPOC_Number(PATH=PATH)\n",
    "# print(EPOC_NUMBER)\n",
    "# print(get_thresholds(PATH=PATH, EPOC_NUMBER=EPOC_NUMBER))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95c2ee-8969-4cf0-973b-d6b44c67cb17",
   "metadata": {},
   "source": [
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ce974b5-3310-4702-8340-bb5e4999d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_network(model, device, graph, test_edges,\n",
    "                     batch_size, DATASET_NAME=\"\", MODEL_NAME=\"\", SOURCE_NODE=0, DST_NODE=0, APPLICATION_NAME=\"\", EPOC_NUMBER=0, TARGET=0):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph = graph.to(device)\n",
    "        x = graph.ndata['feat'].to(device)\n",
    "        e = graph.edata['feat'].to(device).float()\n",
    "        try:\n",
    "            x_pos_enc = graph.ndata['pos_enc'].to(device)\n",
    "            h = model(graph, x, e, x_pos_enc) \n",
    "        except:\n",
    "            h = model(graph, x, e)\n",
    "\n",
    "        test_edges = test_edges.to(device)\n",
    "        \n",
    "#         print(\"Test edges\", test_edges)\n",
    "\n",
    "        test_preds = []\n",
    "        for perm in DataLoader(range(test_edges.size(0)), batch_size):\n",
    "            edge = test_edges[perm].t()\n",
    "            # print(\"edge ==> \",edge, len(edge))\n",
    "            test_preds += [model.edge_predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "#         print(test_preds)\n",
    "        if len(test_edges)==1:\n",
    "            t= test_preds[0]\n",
    "            t =np.expand_dims(t,0)\n",
    "            t = torch.tensor(t)\n",
    "            test_preds = [t]\n",
    "        test_pred = torch.cat(test_preds, dim=0)\n",
    "#         print(test_pred)\n",
    "        \n",
    "    # cutoff_thrshld = get_thresholds(PATH=PATH, EPOC_NUMBER=EPOC_NUMBER)\n",
    "    # cutoff_thrshld = \"{:.12f}\".format(float(cutoff_thrshld))\n",
    "    # count = 0\n",
    "    # print(cutoff_thrshld)\n",
    "    \n",
    "\n",
    "    # for i in range(len(test_pred)):\n",
    "    #     print(test_edges[i],\"=======>\", test_pred[i])\n",
    "    \n",
    "    # for i in range(len(test_pred)):\n",
    "    #     pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "    #     if(pred_score >= cutoff_thrshld):\n",
    "    #         print(test_edges[i],\"=======>\", test_pred[i])\n",
    "    #         count+=1\n",
    "    #     if test_edges[i][1]==TARGET:\n",
    "    #         print(\"ACTUAL ======> \",test_edges[i],\"=======>\", test_pred[i])\n",
    "    \n",
    "    # return count\n",
    "\n",
    "    return test_edges, test_pred\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75fa61f-7f2a-4930-b1dd-ed2e87228a4b",
   "metadata": {},
   "source": [
    "## Get Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "410d0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def get_candidates(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME, SOURCE_ID, TARGET):\n",
    "    node_df_org = pd.read_csv(\"../new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    node_df = node_df_org[node_df_org['new_id']==SOURCE_ID].reset_index(drop=True)\n",
    "    # print(node_df)\n",
    "    total = 0\n",
    "    all_edges = []\n",
    "    try:\n",
    "        file_name = node_df.iloc[0]['file_name']\n",
    "        name = node_df.iloc[0]['name']\n",
    "        start_line = node_df.iloc[0]['start_line']\n",
    "        start_column = node_df.iloc[0]['start_column']\n",
    "        src_id = node_df.iloc[0]['new_id']\n",
    "        start_time = time.time()\n",
    "        test_edges, random_test_edge = get_test_data(file_name, src_id, APPLICATION_NAME)\n",
    "        # print(\"TIME TO GET CANDIATE ===> \", start_time-time.time(),\" seconds\")\n",
    "        start_time = time.time()\n",
    "        if len(test_edges) > 0:\n",
    "            test_edges, test_pred = evaluate_network(\n",
    "                        model, device, graph, test_edges, params['batch_size'], DATASET_NAME=DATASET_NAME, MODEL_NAME=MODEL_NAME, SOURCE_NODE=src_id, APPLICATION_NAME=APPLICATION_NAME, TARGET=TARGET)\n",
    "        # print(\"TIME TO EVALUATE ===> \", start_time-time.time(),\" seconds\")\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    random_test_edges, random_test_pred = {}, {}\n",
    "    return test_edges, test_pred, random_test_edges, random_test_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e580a",
   "metadata": {},
   "source": [
    "## Filter Missing Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac12d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from collections import Counter\n",
    "def filter_missed_edge(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME):\n",
    "    missed_df = pd.read_csv(\"missed_edges/\"+APPLICATION_NAME+\"_missed_call_site_ids.csv\")\n",
    "    ids = missed_df['id'].tolist()\n",
    "    lst = ids\n",
    "#     print(len(lst))\n",
    "    node_df_org = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    node_df = node_df_org[node_df_org['new_id'].isin(lst)].reset_index(drop=True)\n",
    "\n",
    "    total = 0\n",
    "    all_edges = []\n",
    "    lst = []\n",
    "    # exclude_list = ['set', 'require', 'config', 'log', 'import', 'initTestEnvironment', 'platformBrowserDynamicTesting', 'join', 'map', 'bind', 'replace', 'copySync', 'slice', 'test', \n",
    "    # 'reduce', 'nodeResolve', 'commonjs', 'write', 'error', 'exit', 'exec', 'satisfies', 'push', 'warn', 'repeat', 'forEach', 'getRange', 'find', 'includes', 'sort', 'charCodeAt', 'charAt', \n",
    "    # 'substring', 'toString', 'match', 'Error', 'toLowerCase', 'indexOf', 'concat', 'hasOwnProperty', 'removeChild', 'insertBefore', 'createTextNode', 'appendChild', 'createElement', \n",
    "    # 'setAttribute', 'split', 'setTimeout', 'getElementsByTagName', 'addEventListener', 'waitUntil', 'skipWaiting', 'claim', 'resolve', 'SpecReporter', 'cd', 'pop', 'startsWith', 'getInjectables', \n",
    "    # 'unshift', 'trim', 'Dgeni', 'configureInjector', 'get', 'parse', 'debug', 'createDocMessage', '$process', 'filter', 'dirname', 'objectContaining', 'some', 'create', 'getDocFromAlias', \n",
    "    # 'mockLogFactory', 'createDocMessageFactory', 'returnValue', 'callFake', 'addDoc', 'every', 'toUpperCase', 'addAllowed', 'activate', 'relative', 'extname', 'existsSync', 'visit', 'is', \n",
    "    # 'message', 'source', 'fail', 'splice', 'has', 'logMessage', 'any', 'search', 'shift', 'readFileSync', 'spawnSync', 'values', 'getPreviousMajorVersions', 'Package', 'basename', 'getDocs', \n",
    "    # 'add', 'handler', 'regionParser', 'getExampleRegion', 'createPlasterComment', 'call', 'factory', 'getLinkInfo', 'encodeCodeBlock', 'hasActive', 'someActive', 'isActive', 'deactivate', \n",
    "    # 'contains', 'click', 'yellow', 'writeFileSync', 'question', 'red', 'close', 'parser', 'clearLine', 'cursorTo', 'group', 'groupEnd', 'task', 'green', 'info', 'defineProperty', 'runServer', \n",
    "    # 'cwd', 'MagicString', 'generateMap', 'ɵɵdefineComponent', 'ɵɵprojectionDef', 'ɵɵelementStart', 'ɵɵprojection', 'ɵɵelementEnd', 'ɵɵproperty', 'ɵɵadvance', 'ɵɵdefinePipe',\n",
    "    # 'ɵɵdirectiveInject', 'ɵɵtext', 'ɵɵpipe', 'ɵɵpipeBind2', 'ɵɵtextInterpolate2', 'ɵɵdefineDirective', 'ɵɵelement', 'ɵɵnextContext', 'ɵɵtemplate', 'ɵɵinject', 'ɵɵdefineInjectable', \n",
    "    # 'ɵɵHostDirectivesFeature', 'ɵɵgetCurrentView', 'ɵɵlistener', 'ɵɵrestoreView', 'ɵɵresetView', 'unregister', 'on', 'scheduleTask', 'run', 'end', 'define', 'done', 'nativeTimeout', \n",
    "    # 'patchJestObject', 'useFakeTimers', 'useRealTimers', 'getRealSystemTime', 'setSystemTime', 'runAllTicks', 'setInterval', 'runAllTimers', 'clearInterval', 'advanceTimersByTime', \n",
    "    # 'runOnlyPendingTimers', 'clearTimeout', 'advanceTimersToNextTimer', 'clearAllTimers', 'getTimerCount', 'nextTick', 'setup', 'teardown', 'runScript', 'createIndex', 'removeEventListener', \n",
    "    # 'createEvent', 'initEvent', 'dispatchEvent', 'mark', 'measure', 'testRunner', 'then', 'nativeRun', 'before', 'after', 'getElementById', 'insertRow', 'insertCell', 'nativeRaf', \n",
    "    # 'nativeSetTimeout', 'XMLHttpRequest', 'template','truthy', 'falsy', 'cp', 'pushd', 'mkdir', 'chmod', 'rm', 'ls', 'skipOnWin', 'touch',\n",
    "    # 'homedir', 'chdir', 'isSymbolicLink', 'isDirectory', 'chmodSync', 'sync', 'unlinkSync', 'statSync', 'readlinkSync', 'symlinkSync', 'openSync', 'readSync', 'closeSync', 'mkdirSync', \n",
    "    # 'readdirSync', 'utimesSync', 'realpathSync', 'isFile', 'normalize', 'createWriteStream', 'pipe', 'extend', 'execFileSync', 'callback', 'isFIFO', 'localeCompare', 'to', 'cat', 'beforeEach', \n",
    "    # 'resetForTesting', 'always', 'not', 'cmd', 'throws', 'skip', 'regex', 'deepEqual', 'false', 'ShellString', 'cb', 'mv', 'ln', 'getTime', 'dirs', 'echo', 'isBuffer', 'grep', 'errorCode', 'head',\n",
    "    #  'register', 'foo', 'popd', 'pwd', 'sed', 'tail', 'tempdir', 'uniq', '_processStderrWrite', 'which']\n",
    "    \n",
    "    exclude_list = ['require', 'name', 'write', 'log', 'split', 'join', 'slice', 'concat', 'includes', 'match', 'push', 'Error', 'exit', 'replace', 'parseArg', 'on', 'getOptionValueSource', \n",
    "                    'resolve', 'existsSync', 'extname', 'find', 'basename', 'unshift', 'spawn', 'forEach', 'kill', 'fn', 'emit', 'listenerCount', 'attributeName', 'filter', 'shift', 'test', 'opts', \n",
    "                    'startsWith', 'alias', 'map', 'sort', 'padWidth', 'wrap', 'repeat', 'optionTerm', 'optionDescription', 'set', \n",
    "                    'has', 'toUpperCase', 'action', 'parse', 'command', 'mockClear', 'mockRestore', 'promisify', 'execFileAsync', 'assertions', 'mockImplementation', 'cwd', 'any', 'optsWithGlobals']\n",
    "    if 'js-yaml' in DATASET_NAME:\n",
    "        exclude_list = ['call', 'exec', 'toString', 'indexOf', 'toLowerCase', 'toISOString', 'charAt', 'extend', 'listener', 'construct', 'directiveName', 'iterator', 'predicate', \n",
    "                        'representName', 'represent', 'style', 'every', 'inspect', 'readFileSync', 'setOption', 'setValue', 'getElementById', 'fromTextArea', 'readdirSync', 'throws', 'boolean',\n",
    "                        'integer', 'trim', 'skip', \n",
    "                        'strictEqual', 'apply', 'inherits','require', 'Error', 'replace', 'slice', 'push', 'forEach', 'concat', 'toUpperCase', 'test', 'resolve', 'sort', 'join', 'log', \n",
    "                        'map', 'repeat', 'extname', 'basename', 'split', 'startsWith', 'match']\n",
    "    if 'formula-parser' in DATASET_NAME:\n",
    "        exclude_list = ['define', 'call', 'Error', '__webpack_require__', 'reduce', 'concat', 'push', 'apply', 'filter', 'toUpperCase', 'parseDate', 'parseNumber', 'slice', 'map', 'replace', \n",
    "        'indexOf', 'anyIsError', 'AVERAGE', 'COUNT', 'COUNTA', 'MAX', 'MIN', 'S', 'P', 'INC', 'EXC', 'test', 'toString', 'parseNumberArray', 'flatten', 'pop', 'join', 'arrayEach', \n",
    "        'argsToArray', 'ISNUMBER', 'mean', 'numbers', 'cdf', 'pdf', 'inv', 'COMBIN', 'cols', 'normalci', 'tci', 'SUM', 'gammaln', 'stdev', 'sort', 'arrayValuesToNumbers', \n",
    "        'cleanFloat', 'FACT', 'transpose', 'forEach', 'rest', 'substring', 'toLowerCase', 'match', 'substr', 'split', 'ISERROR', 'getDate', 'getMonth', 'getFullYear', 'getHours', \n",
    "        'setDate', 'getDay', 'getMinutes', 'INTL', 'getSeconds', 'toArray', 'func', 'setTimeout', 'passfunc', 'sample', 'fnfunc', 'multiply', 'dot', 'norm', 'aug', 'add', 'subtract', \n",
    "        'divide', 'f', 'sq', 'zscore', 'tscore', 'anovafscore', 'qscore', 'ztest', 'REPT', 'IMREAL', 'IMAGINARY', 'COMPLEX', 'Parser', 'parse', '_error2', 'emit', 'fn', \n",
    "        '_evaluateByOperator2', 'extractLabel', 'toLabel', 'toNumber', 'bessel0', 'bessel1', 'reverse', 'DAYS360', 'callVariable', 'trimEdges', 'evaluateByOperator', 'invertNumber', \n",
    "        'callFunction', 'cellValue', 'rangeValue', 'throwError', 'setInput', 'lex', 'showPosition', 'parseError', 'main', 'clearTimeout', 'require', 'cacheable', 'bind', 'createToken', \n",
    "        'compute', 'rows', 'charAt', '_random_fn', 'xtranspxinv', 'matrixmult', \n",
    "        'next', 'has', 'get', 'set', 'setVariable', '_error', 'resolve', 'on', 'done', 'toMatchObject', 'toBeNull', 'toBe', 'toBeMatchCloseTo', 'toBeCloseTo', \n",
    "        'toBeGreaterThanOrEqual', 'toBeLessThanOrEqual', 'toBeInstanceOf', 'toBeFalsy', 'toBeTruthy', 'toThrow', 'toBeDefined', 'toHaveBeenCalledWith', 'anything']\n",
    "    # exclude_list = ['require', 'concat', 'resolve', 'DefinePlugin', 'Error', 'getAttribute', 'forEach', 'useState', 'createElement', 'getElementById', 'render', 'unmountComponentAtNode',\n",
    "    #   'match', 'renderToString', 'renderComponentToString', 'hydrate', 'log', 'reject', 'appendChild', 'addEventListener', 'transform', 'findDOMNode', 'setTimeout', 'callback', \n",
    "    #   'clearTimeout', 'split', 'getElementsByTagName', 'insertBefore', 'map', 'setItem', 'json', 'indexOf', 'replace', 'includes', 'format', 'push', 'splice', 'printReceived', \n",
    "    #   'jestDiff', 'test', 'hasOwnProperty', 'apply', 'sync', 'webpack', 'error', 'exit', 'toJson', 'hasErrors', 'babelRegister', 'express', 'use', 'compress', 'get', 'static', \n",
    "    #   'fn', 'next', 'readFileSync', 'filter', 'existsSync', 'realpathSync', 'cwd', 'relative', 'bold', 'find', 'resolveFn', 'defaultLoad', 'transformAsync', \n",
    "    #   'defaultTransformSource', 'reactLoad', 'reactTransformSource', 'on', 'slice', 'yellow', 'join', 'cyan', 'green', 'printBuildError', 'red', 'run', 'call', \n",
    "    #   'formatWebpackMessages', 'toLowerCase', 'execSync', 'startsWith', 'dirname', 'request', 'pipe', 'all', 'accepts', 'readFile', 'createFromNodeStream', 'set', \n",
    "    #   'end', 'write', 'flush', 'listen', 'toUpperCase', 'text', 'pathToFileURL', 'fetch', 'useFormStatus', 'ESLint', 'lintFiles', 'some', 'loadFormatter', 'symbolFor', \n",
    "    #   'unshift', 'bind', 'has', 'typeSpecName', 'getName', 'getCurrentStackAddendum', 'getStackAddendum', 'init', '_assign', 'setExtraStackFrame', 'extend', 'spawnSync', \n",
    "    #   'Builder', 'config', 'endsWith', 'lazy', 'x', 'describe', 'beforeEach', 'afterEach', 'getBoundingClientRect', 'dispatchEvent', 'focus', 'testFn', 'clear', 'report', \n",
    "    #   'add', 'getSource', 'insertTextAfter', 'insertTextBefore', 'sort', 'replaceText', 'shift', 'entries', 'pop', 'BigInt', 'delete', 'getScope', 'warn', 'assign', 'for', 'isArray',\n",
    "    #    'toString', 'resetModules', 'jsx', 'renderIntoDocument', 'jsxs', 'gate', 'createReactClass', 'Path', 'move', 'arc', 'line', 'close', 'platform', 'ProvidePlugin', 'exec', \n",
    "    #    'newPage', 'goto', 'waitForSelector', 'evaluate', 'findAllNodes', 'createTestNameSelector', 'gte', 'focusWithin', 'press', 'insertText', 'waitForFunction', 'click', \n",
    "    #    'createTextSelector', 'skip', 'satisfies', 'env', 'repeat', 'toFixed', 'printStore', 'addListener', 'send', 'runAllTimers', 'mockClear', 'emit', 'removeListener', \n",
    "    #    'cb', 'only', 'getDisplayName', 'getDisplayNameForReactElement', 'formatWithStyles', 'gt', 'isPlainObject', 'removeChild', 'getStyleXData', 'setCount', 'default', 'parse', \n",
    "    #    'values', 'mockIf', 'mock', 'inspectHooks', 'xit', 'spyOn', 'checkDCE', 'createHTMLDocument', 'open', 'getNodeForCharacterOffset', 'trim', 'setProperty', 'getSelection', \n",
    "    #    'addRange', 'querySelectorAll', 'remove', 'setAttribute', 'removeAttribute', 'preventDefault', 'injectEventPluginOrder', 'injectEventPluginsByName', \n",
    "    #    'getNodeFromInstance', 'isPropagationStopped', 'normalize', 'identifier', 'generateUidIdentifier', 'cloneDeep', 'stringLiteral', 'booleanLiteral', 'blockStatement', \n",
    "    #    'returnStatement', 'replaceWith', 'assignmentExpression', 'insertAfter', 'expressionStatement', 'callExpression', 'isBlock', 'traverse', 'pushContainer', 'unmock', \n",
    "    #    'scheduleCallback', 'requestPaint', 'unstable_shouldYield', 'now', 'cancelCallback', 'shouldYield', 'waitFor', 'waitForAll', 'unstable_advanceTime', 'assertLog', \n",
    "    #    'unstable_flushExpired', 'wrapCallback', 'wrappedCallback', 'runWithPriority', 'getCurrentPriorityLevel', 'wrappedUserBlockingCallback', 'unstable_flushAll', \n",
    "    #    'requireActual', 'startLoggingProfilingEvents', 'formatProdErrorMessage', 'invokeGuardedCallbackAndCatchFirstError', 'hasCaughtError', 'rethrowCaughtError', \n",
    "    #    'invokeGuardedCallback', 'clearCaughtError', 'gateFn', 'addDefault', 'matchesPattern', 'logicalExpression', 'memberExpression', 'numericLiteral', 'addNamed', \n",
    "    #    'buildCodeFrameError', 'arrowFunctionExpression', 'mean', 'e', 'asyncCopyTo', 'writeFileSync', 'rimraf', '_resolve', 'ncp', 'getBranchCommit', 'reset', 'lookup', 'gray', \n",
    "    #    'white', 'writeHead', 'createServer', 'Table', 'createLogger', 'logger', 'prompt', 'dim', 'addComment', 'RuleTester', 'statSync', 'unlinkSync', 'copyFileSync', \n",
    "    #    'utimesSync', 'setup', 'teardown', 'charAt', 'expectBlock', 'flattenDiagnosticMessageText', \n",
    "    #     'hex', 'readJson', 'writeJson', 'every', 'black', 'ClosureCompiler', 'getSigningToken', 'signFile', 'promisify', 'filesize', 'wrapper']\n",
    "    \n",
    "    if 'express' in DATASET_NAME:\n",
    "        exclude_list = ['require', 'log', 'use', 'next', 'send', 'listen', 'set', 'join', 'urlencoded', 'session', 'hash', 'redirect', 'get', 'destroy', 'render', 'post', 'push', \n",
    "        'format', 'json', 'logger', 'cookieParser', 'cookie', 'download', 'engine', 'static', 'error', 'status', 'Error', 'nextTick', 'enable', 'disable', 'readFile', 'fn', \n",
    "        'escapeHtml', 'on', 'resume', 'parse', 'message', 'methodOverride', 'indexOf', 'method', 'toUpperCase', 'createClient', 'param', 'createError', 'map', 'range', 'delete', \n",
    "        'slice', 'key', 'all', 'put', 'sadd', 'sendFile', 'querySelector', 'vhost', 'extname', 'setEncoding', 'replace', 'filter', 'debug', 'setPrototypeOf', 'resolve', 'bind', \n",
    "        'done', 'handle', 'flatten', 'call', 'forEach', 'emit', 'route', 'path', 'apply', 'function', 'merge', 'toString', 'callback', 'mixin', 'enabled', 'setHeader', 'parseUrl', \n",
    "        'accepts', 'deprecate', 'trust', 'trim', 'substring', 'toLowerCase', 'type', 'isBuffer', 'byteLength', 'from', 'removeHeader', 'end', 'contentDisposition', 'lookup', 'vary', \n",
    "        'concat', 'split', 'append', 'setImmediate', 'onFinished', 'handle_request', 'handle_error', 'exec', 'etag', 'dirname', 'basename', 'isFile', 'timeout', 'after', 'throws', \n",
    "        'setTimeout', 'del', 'header', 'close', 'foobar', 'shout', 'once', 'cb', 'disabled', 'foo', 'alloc', 'write', 'expect', 'AsyncLocalStorage', 'run', 'getStore', 'raw', \n",
    "        'relative', 'sendStatus', 'text', 'acceptsCharset', 'acceptsCharsets', 'acceptsEncoding', \n",
    "        'acceptsEncodings', 'acceptsLanguage', 'acceptsLanguages', 'is', 'attachment', 'jsonp', 'links', 'contentType', 'abort', 'sendfile', 'wetag']\n",
    "    if 'lodash' in DATASET_NAME:\n",
    "        exclude_list = ['createMathOperation', 'apply', 'baseAt', 'baseFlatten', 'func', 'Error', 'log', 'require', 'toLowerCase', 'upperFirst', 'createRound', 'baseClone', 'iteratee', 'call', \n",
    "                    'baseAssignValue', 'cancelAnimationFrame', 'setTimeout', 'clearTimeout', 'now', 'forEach', 'push', 'baseDifference', 'baseWhile', 'slice', 'baseIsEqual', 'test', 'replace', \n",
    "                    'predicate', 'baseFindIndex', 'reverse', 'baseGet', 'castPath', 'toKey', 'isIndex', 'baseIntersection', 'getTag', 'baseIsMatch', 'getMatchData', 'createCaseFirst', 'baseSum', \n",
    "                    'createAssigner', 'baseMerge', 'stringSize', 'createPadding', 'baseProperty', 'basePullAll', 'basePullAt', 'createRange', 'copyArray', 'baseSet', 'baseSortedIndex', \n",
    "                    'baseSortedIndexBy', 'baseSortedUniq', 'hasUnicode', 'stringToArray', 'split', 'concat', 'findIndex', 'each', 'map', 'times', 'create', 'methodName', 'merge', 'add', \n",
    "                    'after', 'ary', 'capped','curry', 'rearg', 'constant', 'defineProperty', 'assign', 'isArray', 'transform', 'range', 'value', 'isEqual', 'includes', 'done', 'difference', \n",
    "                    'uniq', 'clone', 'cloneDeep', 'toString', 'toArray', 'before', 'bindAll', 'bindKey', 'bound', 'toUpperCase', 'reduce', 'chain', '_', 'pop', 'set', 'forOwn', 'isObject', \n",
    "                    'inspect', 'exec', 'valueOf', 'createElement', 'startsWith', 'isElement', 'Ctor', 'join', 'isPlainObject', 'take', 'cond', 'matches', 'throws', 'filter', 'par', 'every', \n",
    "                    'keys', 'partial', 'find', 'mapKeys', 'mapValues', 'reject', 'some', 'sortBy', 'uniqBy', 'funced', 'shift', 'runInContext', 'cancel', 'flush', 'setProperty', 'divide', \n",
    "                    'dropRight', 'drop', 'last', 'endsWith', 'fill', 'zipObject', 'resolve', 'flatten', 'combined', 'sort', 'fromPairs', 'isEven', 'head', 'first', 'identity', 'a', 'invokeMap', \n",
    "                    'isBuffer', 'clear', 'ArrayBuffer', 'CtorA', 'CtorB', 'delete', 'isFinite', 'getElementsByTagName', 'isNaN', 'dirname', 'baseIsNative', 'has', 'prop', 'partialRight', \n",
    "                    'notOk', 'next', 'plant', 'eq', 'bind', 'wrapper', 'lowerFirst', 'Stack', 'MapCache', 'get', 'max', 'memoized', 'mergeWith', 'method', 'methodOf', 'c', 'combo', 'bound2', \n",
    "                    'par2', 'min', 'mixin', 'multiply', 'negate', 'noConflict', 'flatMap', 'mod', 'nthArg', 'castArray', 'isSymbol', 'omit', 'once', 'over', 'rearged', 'rest', 'round', 'spread', \n",
    "                    'subtract', 'takeRight', 'square', 'template', 'compiled', 'throttled', 'throttle', 'withTrailing', 'withoutTrailing', 'toLower', 'toUpper', 'unary', 'match', 'attempt', \n",
    "                    'wrap', 'p', 'wrapped', 'charsStartIndex', 'charsEndIndex', 'baseToString', 'baseUniq', 'baseUpdate', 'baseXor', 'baseZipObject']\n",
    "    touple_lst = []\n",
    "    for i in range(len(node_df)):\n",
    "        try:\n",
    "            file_name = node_df.iloc[i]['file_name']\n",
    "            name = node_df.iloc[i]['name']\n",
    "            start_line = node_df.iloc[i]['start_line']\n",
    "            start_column = node_df.iloc[i]['start_column']\n",
    "            src_id = node_df.iloc[i]['new_id']\n",
    "            if name not in exclude_list:\n",
    "            # if name =='fn':\n",
    "            # if pd.isnull(name):\n",
    "                lst.append(name)\n",
    "                # print(file_name, name, start_line, start_column, src_id)\n",
    "                touple_lst.append((file_name, name, start_line, start_column, src_id))\n",
    "                \n",
    "        except:\n",
    "            # traceback.print_stack()\n",
    "            raise\n",
    "    # d = Counter(lst)\n",
    "    # print(d)\n",
    "    # exclude_lst = []\n",
    "    # for key in d:\n",
    "    #     if d[key]>1:\n",
    "    #         exclude_lst.append(key)\n",
    "    # print(exclude_lst)\n",
    "    return touple_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df258fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'GatedGCN'\n",
    "# to_do_list = ['commander.js']\n",
    "# app_list = ['commander.js']\n",
    "# to_do_list = ['lodash', 'formula-parser', 'express','js-yaml']\n",
    "# app_list = ['lodash', 'formula-parser', 'express', 'js-yaml']\n",
    "\n",
    "to_do_list = ['js-yaml']\n",
    "app_list = ['js-yaml']\n",
    "\n",
    "# print(os.getcwd())\n",
    "# if \"experimental_copy_redo\" not in str(os.getcwd()):\n",
    "#     os.chdir('experimental_copy_redo/')\n",
    "# print(os.getcwd())\n",
    "\n",
    "for i in range(len(to_do_list)):\n",
    "    APPLICATION_NAME = app_list[i]\n",
    "    DATASET_NAME = 'NEW_DATASET--'+APPLICATION_NAME\n",
    "    PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "    EPOC_NUMBER = get_EPOC_Number(PATH=PATH)\n",
    "    # EPOC_NUMBER = 15\n",
    "    dataset = load_datset(DATASET_NAME)\n",
    "    net_params, params = set_parameters(MODEL_NAME, dataset, DATASET_NAME)\n",
    "    model, graph = train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME)\n",
    "    touple_list = filter_missed_edge(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME)\n",
    "    print(len(touple_list))\n",
    "    output_file = open(APPLICATION_NAME+\"_missing_edge_log_\"+MODEL_NAME+\"_with_epoc_\"+str(EPOC_NUMBER)+\"_new.txt\",\"w+\")\n",
    "    cutoff_thrshld = 0.9\n",
    "    node_df_org = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    \n",
    "    \n",
    "    for i in range(len(touple_list)):\n",
    "        try:\n",
    "            file_name, name, start_line, start_column, src_id = touple_list[i]\n",
    "            test_edges, test_pred, random_test_edges, random_test_pred = get_candidates(PATH, EPOC_NUMBER, model, graph, params, DATASET_NAME, MODEL_NAME, APPLICATION_NAME, src_id, 0)\n",
    "            # print(random_test_pred)\n",
    "            count= 0\n",
    "            output_file.write(\"Source =====>\"+file_name+\" \"+str(name)+\" \"+str(start_line)+\" \"+str(start_column)+\" \"+str(src_id)+\"\\n\")\n",
    "            output_str=\"\"\n",
    "            for i in range(len(test_pred)):\n",
    "                dst_id = test_edges[i][1].item()\n",
    "                node_df = node_df_org[node_df_org['new_id']==dst_id].reset_index(drop=True)\n",
    "                file_name = node_df.iloc[0]['file_name']\n",
    "                name = node_df.iloc[0]['name']\n",
    "                start_line = node_df.iloc[0]['start_line']\n",
    "                start_column = node_df.iloc[0]['start_column']\n",
    "                src_id = node_df.iloc[0]['new_id']\n",
    "                pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "                output_str+=file_name+\" \"+str(name)+\" \"+str(start_line)+\" \"+str(start_column)+\" \"+str(src_id)+\" =======> \"+str(pred_score)+\"\\n\"\n",
    "                # output_file.write(str(test_edges[i])+\"=======>\"+str(test_pred[i])+\"\\n\")\n",
    "                # pred_score = \"{:.12f}\".format(float(test_pred[i].item()))\n",
    "                if(float(pred_score) >= cutoff_thrshld):\n",
    "                    print(test_edges[i],\"=======>\", test_pred[i])\n",
    "                    count+=1\n",
    "            \n",
    "            random_edge_above_threshold = 0\n",
    "            for i in range(len(random_test_pred)):\n",
    "                pred_score = \"{:.12f}\".format(float(random_test_pred[i].item()))\n",
    "                if(float(pred_score) >= cutoff_thrshld):\n",
    "                    random_edge_above_threshold+=1\n",
    "            \n",
    "            output_str+=\"Total Relevent edge above \"+str(cutoff_thrshld)+\" ===>  \"+str(count)+\"/\"+str(len(test_pred))+\"\\n\"\n",
    "            output_str+=\"Total Random edge above \"+str(cutoff_thrshld)+\" ===>  \"+str(random_edge_above_threshold)+\"/1000\\n\\n\\n\"\n",
    "            output_file.write(output_str)\n",
    "            output_file.flush()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "# #     plot_graph(rank_list, APPLICATION_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8d9db",
   "metadata": {},
   "source": [
    "## TEST TRUE EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_edge(APPLICATION_NAME):\n",
    "    df = pd.read_csv('leftout_'+APPLICATION_NAME+'.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58323174",
   "metadata": {},
   "source": [
    "## Plot graphs for TPR vs EPOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(main_lst, APPLICATION_NAME, MODEL_NAME):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    try:\n",
    "        os.makedirs('figures/'+APPLICATION_NAME)\n",
    "    except:\n",
    "        pass\n",
    "    # try:\n",
    "    #     os.makedirs('figures/'+APPLICATION_NAME+\"/\"+MODEL_NAME)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    for i in range(len(main_lst[0])):\n",
    "        lst = [tensor[i].item() for tensor in main_lst]\n",
    "        # plt.plot(lst)\n",
    "\n",
    "        max_index = lst.index(max(lst))\n",
    "        print(max_index)\n",
    "        sns.lineplot(x=range(len(lst)), y=lst)\n",
    "        \n",
    "        # plt.show()\n",
    "    plt.savefig('figures/'+APPLICATION_NAME+\"/\"+MODEL_NAME+\"_fpr_vs_epoc.pdf\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee67f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_index(main_lst):\n",
    "    index_list = []\n",
    "    for i in range(len(main_lst[0])):\n",
    "        lst = [tensor[i].item() for tensor in main_lst]\n",
    "        max_index = lst.index(max(lst))\n",
    "        index_list.append(max_index)\n",
    "        # sns.lineplot(x=range(len(lst)), y=lst)\n",
    "        # plt.xlabel('X-axis Label')\n",
    "        # plt.ylabel('Y-axis Label')\n",
    "        # plt.title('Plot of a List of Values')\n",
    "        # plt.show()\n",
    "        # plt.savefig(\"figures/\"+str(i)+\".pdf\")\n",
    "        # plt.close()\n",
    "    print(index_list)\n",
    "    print(np.median(index_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122372be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'GatedGCN'\n",
    "\n",
    "# to_do_list = ['formula-parser']\n",
    "# app_list = ['formula-parser']\n",
    "\n",
    "# # print(os.getcwd())\n",
    "# # if \"experimental_copy_redo\" not in str(os.getcwd()):\n",
    "# #     os.chdir('experimental_copy_redo/')\n",
    "# # print(os.getcwd())\n",
    "\n",
    "# for i in range(len(to_do_list)):\n",
    "#     main_lst = []\n",
    "#     APPLICATION_NAME = app_list[i]\n",
    "#     DATASET_NAME = 'NEW_DATASET--'+APPLICATION_NAME\n",
    "#     PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "#     EPOCS = get_EPOC_Number(PATH=PATH)\n",
    "#     dataset = load_datset(DATASET_NAME)\n",
    "#     net_params, params = set_parameters(MODEL_NAME, dataset, DATASET_NAME)\n",
    "#     for EPOC_NUMBER in range(1,EPOCS+1):    \n",
    "#         model, graph = train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME)\n",
    "#         test_df = get_function_edge(\"../prune_new/\"+ APPLICATION_NAME +'_function_edges.csv')\n",
    "#         # print(test_edges)\n",
    "#         # output_file = open(APPLICATION_NAME+\"_missing_edge_log.txt\",\"w+\")\n",
    "#         node_df_org = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "#         test_edges = torch.from_numpy(test_df.to_numpy())\n",
    "\n",
    "#         test_edges, test_pred = evaluate_network(\n",
    "#                             model, device, graph, test_edges, params['batch_size'], DATASET_NAME=DATASET_NAME, MODEL_NAME=MODEL_NAME, SOURCE_NODE=0, APPLICATION_NAME=APPLICATION_NAME, TARGET=0)\n",
    "#         cutoff_thrshld = 0.8\n",
    "#         # print(test_pred)\n",
    "#         main_lst.append(test_pred)\n",
    "#     plot_figure(main_lst, APPLICATION_NAME, MODEL_NAME)\n",
    "#     get_optimal_index(main_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e9a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'GatedGCN'\n",
    "\n",
    "to_do_list = ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "app_list =  ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "\n",
    "# to_do_list = ['mathjs']\n",
    "# app_list =  ['mathjs']\n",
    "\n",
    "\n",
    "for i in range(len(to_do_list)):\n",
    "    main_lst = []\n",
    "    APPLICATION_NAME = app_list[i]\n",
    "    DATASET_NAME = 'NEW_DATASET--'+APPLICATION_NAME\n",
    "    PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "    EPOCS = get_EPOC_Number(PATH=PATH)\n",
    "    print(EPOCS)\n",
    "    dataset = load_datset(DATASET_NAME)\n",
    "    net_params, params = set_parameters(MODEL_NAME, dataset, DATASET_NAME)\n",
    "    EPOC_NUMBER = EPOCS\n",
    "    model, graph = train_model(dataset, EPOC_NUMBER, APPLICATION_NAME, net_params, params, MODEL_NAME)\n",
    "    test_df = get_function_edge(APPLICATION_NAME)\n",
    "    node_df_org = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    test_edges = torch.from_numpy(test_df.to_numpy())\n",
    "\n",
    "    test_edges, test_pred = evaluate_network(\n",
    "                        model, device, graph, test_edges, params['batch_size'], DATASET_NAME=DATASET_NAME, MODEL_NAME=MODEL_NAME, SOURCE_NODE=0, APPLICATION_NAME=APPLICATION_NAME, TARGET=0)\n",
    "    cutoff_thrshld = 0.8\n",
    "    # main_lst.append(test_pred)\n",
    "    # plot_figure(main_lst, APPLICATION_NAME, MODEL_NAME)\n",
    "    # get_optimal_index(main_lst)\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(test_pred)\n",
    "\n",
    "    # Create a histogram plot using Seaborn\n",
    "    sns.histplot(test_pred, bins=10, kde=True, color='skyblue')\n",
    "\n",
    "    # Customize the plot (optional)\n",
    "    plt.title('Histogram Plot')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Show the plot\n",
    "    # plt.show()\n",
    "    plt.savefig(\"figures/\"+APPLICATION_NAME+\"_histogram_\"+MODEL_NAME+\".pdf\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3066a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(src):\n",
    "    node_df_org = pd.read_csv(\"../prune_new/\"+APPLICATION_NAME+\"_node.csv\")\n",
    "    node_df = node_df_org[node_df_org['new_id']==src].reset_index(drop=True)\n",
    "    file_name = node_df.iloc[0]['file_name']\n",
    "\n",
    "    return file_name\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ee529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "to_do_list = ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "app_list =  ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "\n",
    "# to_do_list = ['mathjs']\n",
    "# app_list =  ['mathjs']\n",
    "\n",
    "\n",
    "for APPLICATION_NAME in to_do_list:\n",
    "    try:\n",
    "        print(APPLICATION_NAME)\n",
    "        df = pd.read_csv(\"leftout_\"+APPLICATION_NAME+\".csv\")\n",
    "        # print(df)\n",
    "        dst_dict = dict(df.values)\n",
    "\n",
    "        main_lst = []\n",
    "        lst = []\n",
    "        with open(APPLICATION_NAME+\"_missing_edge_log_GatedGCN.txt\", \"r+\") as in_file:\n",
    "            for line in in_file:\n",
    "                if len(line.strip())==0:\n",
    "                    temp_lst =[]\n",
    "                    for x in lst:\n",
    "                        temp_lst.append(x)\n",
    "                    if len(temp_lst)>0:\n",
    "                        main_lst.append(temp_lst)\n",
    "                    lst =[]\n",
    "                else:\n",
    "                    lst.append(line)\n",
    "        count = 0\n",
    "        print(len(main_lst))\n",
    "        rank_lst =[]\n",
    "        for lst in main_lst:\n",
    "            node_lst = []\n",
    "            pred_lst = []\n",
    "            for line in lst:\n",
    "                if \"Total edge above\" not in line and \"RANK 1 number of edge\" not in line:\n",
    "                    if 'Source =====>' in line:\n",
    "                        parts = line.split(\" \")\n",
    "                        src = int(parts[-1].strip())\n",
    "                    else:\n",
    "                        parts = line.split(\" \")\n",
    "                        # print(parts)\n",
    "                        dst = int(parts[-3].strip())\n",
    "                        value = float(parts[-1].strip())\n",
    "                        # print(dst, value)\n",
    "                        node_lst.append(dst)\n",
    "                        pred_lst.append(value)\n",
    "            \n",
    "            result_df = pd.DataFrame(list(zip(node_lst, pred_lst)), columns =['id', 'val'])\n",
    "            result_df = result_df.sort_values(by=['val'], ascending=False).reset_index(drop=True)\n",
    "            \n",
    "            if len(result_df)>0:\n",
    "                TARGET = dst_dict[src]\n",
    "                # first_index = result_df.iloc[0]['id']\n",
    "                # # print(TARGET, first_index)\n",
    "                # if first_index == TARGET:\n",
    "                #     count+=1\n",
    "                found = False\n",
    "                for i in range(len(result_df)):\n",
    "                    id = result_df.iloc[i]['id']\n",
    "                    if id == TARGET:\n",
    "                        rank_lst.append(i)\n",
    "                        found = True\n",
    "                # if not found:\n",
    "                #     print(\"NOT FOUND ====> \")\n",
    "                #     file_name = get_file_name(src)\n",
    "                #     dst_file = get_file_name(TARGET)\n",
    "                #     print(src, TARGET, file_name, dst_file)\n",
    "                #     print(result_df)\n",
    "\n",
    "        count_dict={}\n",
    "        for i in range(0, 22):\n",
    "            count_dict[i] = 0\n",
    "        xticks_list=[]\n",
    "        for x in rank_lst:\n",
    "            if x >20:\n",
    "                if 21 in count_dict:\n",
    "                    count= count_dict[21]\n",
    "                    count_dict[21]=count+1\n",
    "                else:\n",
    "                    count_dict[21]=1\n",
    "            else:\n",
    "                if x in count_dict:\n",
    "                    count= count_dict[x]\n",
    "                    count_dict[x]=count+1\n",
    "                else:\n",
    "                    count_dict[x]=1\n",
    "                    \n",
    "        for x in range(21):\n",
    "            xticks_list.append(str(x))\n",
    "        xticks_list.append('20+')\n",
    "        \n",
    "        count_dict = dict(sorted(count_dict.items()))\n",
    "        print(count_dict)\n",
    "        print(xticks_list)\n",
    "        print(APPLICATION_NAME, \"======> \", count, count/len(main_lst)*100)\n",
    "        # len(rank_lst)\n",
    "        # print(rank_list)\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "\n",
    "        try:\n",
    "            plt.figure(figsize=(16, 8))\n",
    "            categories = list(count_dict.keys())\n",
    "            counts = list(count_dict.values())\n",
    "\n",
    "            # Create a bar plot using Seaborn\n",
    "            ax = sns.barplot(x=categories, y=counts)\n",
    "            plt.xticks(range(len(xticks_list)), xticks_list)\n",
    "            plt.title('Histogram of Candidate Ranking')\n",
    "            plt.xlabel('Ranking')\n",
    "            plt.ylabel('Count')\n",
    "            plt.savefig(\"candidate_figures/positive_\"+APPLICATION_NAME+\".pdf\")\n",
    "            plt.close()\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "APPLICATION_NAME = 'express'\n",
    "f = open('../connected_files/'+APPLICATION_NAME+'_dependency_graph.json')\n",
    "data = json.load(f)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"leftout_\"+APPLICATION_NAME+\".csv\")\n",
    "# print(df)\n",
    "dst_dict = dict(df.values)\n",
    "for src in dst_dict:\n",
    "    TARGET = dst_dict[src]\n",
    "    file_name = get_file_name(src)\n",
    "    dst_file = get_file_name(TARGET)\n",
    "    # print(src, TARGET, file_name, dst_file)\n",
    "    if file_name!=dst_file:\n",
    "        if file_name not in data:\n",
    "            print(file_name, src, dst_file)\n",
    "            # print(file_name==dst_file)\n",
    "            # pass\n",
    "        else:\n",
    "            lst = data[file_name]\n",
    "            if dst_file not in lst:\n",
    "                print(src, TARGET, file_name, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLICATION_NAME = \"formula-parser\"\n",
    "print(APPLICATION_NAME)\n",
    "# df = pd.read_csv(\"leftout_\"+APPLICATION_NAME+\".csv\")\n",
    "# # print(df)\n",
    "# dst_dict = dict(df.values)\n",
    "\n",
    "main_lst = []\n",
    "lst = []\n",
    "should_start = False\n",
    "what_we_looking_for = \"/Users/masudulhasanmasudbhuiyan/Documents/gitlab/libraries/formula-parser/dist/formula-parser.js apply 158 15 371\"\n",
    "with open(APPLICATION_NAME+\"_missing_edge_log_GatedGCN_with_epoc_174_new.txt\", \"r+\") as in_file:\n",
    "    for line in in_file:\n",
    "        if what_we_looking_for in line:\n",
    "            lst.append(line)\n",
    "            should_start = True\n",
    "        else:\n",
    "            if should_start:\n",
    "                if len(line.strip())==0:\n",
    "                    temp_lst =[]\n",
    "                    for x in lst:\n",
    "                        temp_lst.append(x)\n",
    "                    if len(temp_lst)>0:\n",
    "                        main_lst.append(temp_lst)\n",
    "                    lst =[]\n",
    "                    should_start = False\n",
    "                else:\n",
    "                    lst.append(line)\n",
    "\n",
    "count = 0\n",
    "print(len(main_lst))\n",
    "rank_lst =[]\n",
    "for lst in main_lst:\n",
    "    node_lst = []\n",
    "    pred_lst = []\n",
    "    for line in lst:\n",
    "        if \"Total \" not in line and \"RANK 1 number of edge\" not in line:\n",
    "            if 'Source =====>' in line:\n",
    "                parts = line.split(\" \")\n",
    "                src = int(parts[-1].strip())\n",
    "            else:\n",
    "                parts = line.split(\" \")\n",
    "                # print(parts)\n",
    "                dst = int(parts[-3].strip())\n",
    "                value = float(parts[-1].strip())\n",
    "                # print(dst, value)\n",
    "                node_lst.append(dst)\n",
    "                pred_lst.append(value)\n",
    "    \n",
    "    result_df = pd.DataFrame(list(zip(node_lst, pred_lst)), columns =['id', 'val'])\n",
    "    result_df = result_df.sort_values(by=['val'], ascending=False).reset_index(drop=True)\n",
    "    print(len(result_df))\n",
    "    if len(result_df)>0:\n",
    "        TARGET = 380\n",
    "        # first_index = result_df.iloc[0]['id']\n",
    "        # # print(TARGET, first_index)\n",
    "        # if first_index == TARGET:\n",
    "        #     count+=1\n",
    "        found = False\n",
    "        for i in range(len(result_df)):\n",
    "            id = result_df.iloc[i]['id']\n",
    "            if id == TARGET:\n",
    "                print(\"RANK ====> \", i)\n",
    "        # if not found:\n",
    "        #     print(\"NOT FOUND ====> \")\n",
    "        #     file_name = get_file_name(src)\n",
    "        #     dst_file = get_file_name(TARGET)\n",
    "        #     print(src, TARGET, file_name, dst_file)\n",
    "        #     print(result_df)\n",
    "\n",
    "# print(APPLICATION_NAME, \"======> \", count, count/len(main_lst)*100)\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# try:\n",
    "#     plt.figure(figsize=(16, 8))\n",
    "#     sns.distplot(rank_lst, hist=True, kde=False, \n",
    "#                 bins=int(max(rank_lst)/2), color = 'blue',\n",
    "#                 hist_kws={'edgecolor':'black'})\n",
    "#     # Add labels\n",
    "\n",
    "#     plt.title('Histogram of Candidate Ranking')\n",
    "#     plt.xlabel('Ranking')\n",
    "#     plt.ylabel('Count')\n",
    "#     plt.savefig(\"candidate_figures/positive_\"+APPLICATION_NAME+\".pdf\")\n",
    "#     plt.close()\n",
    "# except:\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456966be",
   "metadata": {},
   "source": [
    "## Plot comaparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e458451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(FILE_PATH, dst_dict):\n",
    "    main_lst = []\n",
    "    lst = []\n",
    "    with open(FILE_PATH, \"r+\") as in_file:\n",
    "        for line in in_file:\n",
    "            if len(line.strip())==0:\n",
    "                temp_lst =[]\n",
    "                for x in lst:\n",
    "                    temp_lst.append(x)\n",
    "                if len(temp_lst)>0:\n",
    "                    main_lst.append(temp_lst)\n",
    "                lst =[]\n",
    "            else:\n",
    "                lst.append(line)\n",
    "    count = 0\n",
    "    print(len(main_lst))\n",
    "    rank_lst =[]\n",
    "    for lst in main_lst:\n",
    "        node_lst = []\n",
    "        pred_lst = []\n",
    "        for line in lst:\n",
    "            if \"Total edge above\" not in line and \"RANK 1 number of edge\" not in line:\n",
    "                if 'Source =====>' in line:\n",
    "                    parts = line.split(\" \")\n",
    "                    src = int(parts[-1].strip())\n",
    "                else:\n",
    "                    parts = line.split(\" \")\n",
    "                    dst = int(parts[-3].strip())\n",
    "                    value = float(parts[-1].strip())\n",
    "                    node_lst.append(dst)\n",
    "                    pred_lst.append(value)\n",
    "        \n",
    "        result_df = pd.DataFrame(list(zip(node_lst, pred_lst)), columns =['id', 'val'])\n",
    "        result_df = result_df.sort_values(by=['val'], ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        if len(result_df)>0:\n",
    "            TARGET = dst_dict[src]\n",
    "            found = False\n",
    "            for i in range(len(result_df)):\n",
    "                id = result_df.iloc[i]['id']\n",
    "                if id == TARGET:\n",
    "                    rank_lst.append(i)\n",
    "                    found = True\n",
    "\n",
    "    count_dict={}\n",
    "    for i in range(0, 22):\n",
    "        count_dict[i] = 0\n",
    "    for x in rank_lst:\n",
    "        if x >20:\n",
    "            if 21 in count_dict:\n",
    "                count= count_dict[21]\n",
    "                count_dict[21]=count+1\n",
    "            else:\n",
    "                count_dict[21]=1\n",
    "        else:\n",
    "            if x in count_dict:\n",
    "                count= count_dict[x]\n",
    "                count_dict[x]=count+1\n",
    "            else:\n",
    "                count_dict[x]=1\n",
    "    count_dict = dict(sorted(count_dict.items()))\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "to_do_list = ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "app_list =  ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "\n",
    "# to_do_list = ['mathjs']\n",
    "# app_list =  ['mathjs']\n",
    "\n",
    "\n",
    "for APPLICATION_NAME in to_do_list:\n",
    "    try:\n",
    "        print(APPLICATION_NAME)\n",
    "        df = pd.read_csv(\"leftout_\"+APPLICATION_NAME+\".csv\")\n",
    "        # print(df)\n",
    "        dst_dict = dict(df.values)\n",
    "        count_dict = get_dict(APPLICATION_NAME+\"_missing_edge_log_GatedGCN.txt\", dst_dict)\n",
    "        without_dynamic_dict = get_dict(\"../prune+bidirectional+semantic_edge/\"+APPLICATION_NAME+\"_missing_edge_log_GatedGCN.txt\", dst_dict)\n",
    "\n",
    "        key_list =[]\n",
    "        value_lst =[]\n",
    "        tag_lst =[]\n",
    "\n",
    "        for k in count_dict:\n",
    "            key_list.append(k)\n",
    "            value_lst.append(count_dict[k])\n",
    "            tag_lst.append(\"With Dynamic Edges\")\n",
    "        \n",
    "        for k in without_dynamic_dict:\n",
    "            key_list.append(k)\n",
    "            value_lst.append(without_dynamic_dict[k])\n",
    "            tag_lst.append(\"With Only Static Edges\")\n",
    "\n",
    "        df = pd.DataFrame({\"key\":key_list,\"value\":value_lst, \"tag\":tag_lst})\n",
    "        xticks_list = []\n",
    "        for x in range(21):\n",
    "            xticks_list.append(str(x))\n",
    "        xticks_list.append('20+')\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        ax = sns.barplot(x='key', y='value', hue='tag', data=df)\n",
    "        plt.xticks(range(len(xticks_list)), xticks_list)\n",
    "        plt.title('Histogram of Candidate Ranking')\n",
    "        plt.xlabel('Ranking')\n",
    "        plt.ylabel('Count')\n",
    "        plt.savefig(\"candidate_figures/comparison_\"+APPLICATION_NAME+\".pdf\")\n",
    "        plt.close()\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14aaebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula-parser\n",
      "285\n",
      "[0.956418812275, 0.608633637428, 0.102923691273, 0.97315967083, 1.5855669e-05, 0.092479988933, 0.100111782551, 0.577293515205, 0.29795050621, 0.998141527176, 0.98259729147, 0.992829501629, 0.585661590099, 0.492752701044, 0.58483338356, 0.896153986454, 0.898507773876, 0.996859312057, 0.934717476368, 0.981552183628, 0.997934341431, 0.850268244743, 0.943106710911, 0.933285176754, 0.062218494713, 0.863203108311, 0.637994468212, 0.964657127857, 0.950586140156, 0.961112260818, 0.949229836464, 0.956417322159, 0.976387500763, 0.97441226244, 0.995109260082, 0.919965088367, 0.972142517567, 0.974405229092, 0.967862904072, 0.955595493317, 0.751520216465, 0.509191095829, 0.408225893974, 0.951177895069, 0.909328877926, 0.183220922947, 0.965189874172, 0.883240640163, 0.914704740047, 0.998075962067, 0.998091518879, 0.996591210365, 0.997631072998, 0.082659944892, 0.997458994389, 0.996176719666, 0.000658963982, 0.868286967278, 0.05276349932, 0.09954932332, 0.936909079552, 0.00024232571, 0.908931016922, 0.99969792366, 0.013682294637, 0.0066073942, 0.999717414379, 0.99970883131, 0.055391397327, 0.998916983604, 0.998646438122, 0.995659768581, 0.973744452, 0.865464031696, 0.994542956352, 0.997526586056, 0.996197342873, 0.952240228653, 0.992516219616, 0.981341600418, 0.984561443329, 0.987085044384, 0.996057748795, 0.998440921307, 0.999014854431, 0.999014854431, 0.321515351534, 0.009538559243, 0.953595817089, 0.999970316887, 0.999162554741, 0.999296784401, 0.997428238392, 0.999697208405, 0.964515328407, 0.862344503403, 0.875239253044, 0.999733388424, 0.999996185303, 0.999997496605, 0.999997377396, 0.999997377396, 0.999997377396, 0.999994277954, 0.999994277954, 0.999992370605, 0.999994516373, 0.999995112419, 0.999990105629, 0.999995112419, 0.999993085861, 0.999993085861, 0.999993085861, 0.999995470047, 0.999990940094, 0.999993085861, 0.999112308025, 0.999903917313, 0.999932050705, 0.999932050705, 0.999921441078, 0.999921441078, 0.999921441078, 0.999936938286, 0.99958127737, 0.999903917313, 0.999847531319, 0.99986076355, 0.99986076355, 0.999903917313, 0.999981641769, 0.999979019165, 0.999973893166, 0.999952554703, 0.999952316284, 0.999833106995, 0.99980443716, 0.999954938889, 0.999952316284, 0.999995350838, 0.99999666214, 0.999993801117, 0.999994754791, 0.999981284142, 0.999995708466, 0.999995708466, 0.999995708466, 0.999994754791, 0.989382147789, 0.976142585278, 0.989942312241, 0.989943146706, 0.990508913994, 0.98995578289, 0.991715252399, 0.991266906261, 0.98798418045, 0.989942312241, 0.989942312241, 0.989943027496, 0.989943146706, 0.989912688732, 0.989912569523, 0.989943146706, 0.989943146706, 0.989943146706, 0.989943146706, 0.990073204041, 0.98995578289, 0.98995578289, 0.987222135067, 0.987222015858, 0.989942312241, 0.990073084831, 0.989943146706, 0.989942312241, 0.989942193031, 0.990074038506, 0.9998960495, 0.999976634979, 0.980010569096, 0.980266928673, 0.984865427017, 0.980266928673, 0.980266928673, 0.969789326191, 0.976257324219, 0.976257324219, 0.97673368454, 0.976733326912, 0.976733446121, 0.970775961876, 0.976733326912, 0.976733326912, 0.985912382603, 0.973660945892, 0.970776081085, 0.970775842667, 0.98250246048, 0.998375654221, 0.999884605408, 0.974409222603, 0.998254716396, 0.977835714817, 0.978986561298, 0.978986561298, 0.97893768549, 0.969476997852, 0.977333545685, 0.999899148941, 0.979887962341, 0.979881048203, 0.985912382603, 0.999896168709, 0.982058703899, 0.988513767719, 0.986493945122, 0.999239802361, 0.999842643738, 0.999686121941, 0.981665074825, 0.963483333588, 0.976504504681, 0.976720392704, 0.981527745724, 0.999991416931, 0.999990224838, 0.999990224838, 0.999988079071, 0.999988079071, 0.999990224838, 0.999988079071, 0.999988079071, 0.999996542931, 0.999990224838, 0.999990224838, 0.999988079071, 0.999988079071, 0.999985218048, 0.999991416931, 0.999755322933, 0.999925613403, 0.999925613403, 0.99999666214, 0.999996900558, 0.99999666214, 0.999995589256, 0.999994754791, 0.999994277954, 0.999921798706, 0.999861478806, 0.999943852425, 0.99998998642, 0.99961411953, 0.999566376209, 0.999815642834, 0.999606311321, 0.999566376209, 0.999606311321, 0.97371417284, 0.994628965855, 0.995030283928, 0.996140778065, 0.998771369457, 0.998771369457, 0.988264799118, 0.999589383602, 0.999803245068, 0.996265351772, 0.993933022022, 0.997969329357, 0.997060000896, 0.996745228767, 0.997242808342, 0.98532050848, 0.998947918415, 0.434857577085, 0.30608317256, 0.037328705192, 0.490489810705, 0.487895965576, 0.847563564777, 0.984681963921, 0.984681963921]\n",
      "2798\n",
      "284\n",
      "lodash\n",
      "227\n",
      "[0.862442195415, 0.403917580843, 0.999894857407, 0.999861598015, 0.999999880791, 0.999971032143, 0.577055871487, 0.000201922943, 0.997465014458, 0.375927805901, 1.84482e-07, 0.001155699254, 0.946380376816, 0.999980330467, 0.756109535694, 0.989981114864, 3.7018e-08, 0.987393736839, 0.992322742939, 0.997246026993, 0.998322069645, 0.760726809502, 0.999964952469, 0.999964594841, 0.983586251736, 0.57249468565, 0.979339718819, 0.763517618179, 0.99906784296, 0.633008539677, 0.162635222077, 0.998303890228, 0.970851242542, 0.999425411224, 0.754062116146, 0.999754607677, 0.999880313873, 0.999528288841, 0.999892354012, 0.999891161919, 0.99930870533, 0.952181339264, 0.418514937162, 0.141093105078, 0.001131394645, 0.014830937609, 0.252197623253, 0.160072565079, 0.963218927383, 0.373175323009, 0.647804796696, 0.979793965816, 0.997833073139, 0.874052524567, 0.692247509956, 0.966067910194, 0.935943186283, 0.824158787727, 0.996486067772, 0.120681978762, 0.460267692804, 0.989006757736, 0.167872726917, 0.167872726917, 0.920157730579, 0.057770259678, 0.036990724504, 0.981521725655, 0.999201595783, 0.73659658432, 0.928278326988, 0.87399315834, 0.999919056892, 0.996906578541, 0.997600615025, 0.999790251255, 0.976751089096, 0.952133357525, 0.999628663063, 0.293635338545, 0.823132157326, 0.999805748463, 0.978976547718, 0.978976547718, 0.918474853039, 0.90839111805, 0.741408288479, 0.227563306689, 0.915576279163, 0.999869465828, 0.999533772469, 0.998976230621, 0.987460136414, 0.976671278477, 2.2895e-08, 0.986020743847, 0.985029041767, 0.9876126647, 0.992354512215, 0.996607780457, 0.942788958549, 0.97775799036, 0.708138227463, 0.928094685078, 0.977968275547, 0.431092143059, 0.627710103989, 0.359120547771, 0.220940202475, 0.998832762241, 0.999311208725, 0.999553024769, 0.997913897038, 0.996563255787, 0.997147381306, 0.999319314957, 0.996473491192, 0.998486220837, 0.943686306477, 0.78546744585, 0.985329985619, 0.999706804752, 0.989495098591, 0.999563872814, 0.842715442181, 0.961525022984, 0.535315096378, 0.948799014091, 0.334246665239, 0.963555932045, 0.070376113057, 0.037819150835, 0.745955765247, 0.932612538338, 0.999992847443, 0.999902248383, 0.99992287159, 0.960770249367, 0.988082408905, 0.98056179285, 0.980486154556, 0.997825503349, 0.997569382191, 0.999876737595, 0.849852085114, 0.655577480793, 0.87982904911, 0.650933802128, 0.655817866325, 0.024289315566, 0.977464258671, 0.29586160183, 0.955361187458, 0.958107769489, 0.999681353569, 0.981732666492, 0.998683393002, 0.88936406374, 0.749818623066, 0.999736249447, 0.877349853516, 0.127234697342, 0.629324376583, 0.988531947136, 0.995538175106, 0.237443581223, 0.609674930573, 0.965757131577, 0.970996618271, 0.876919984818, 0.281312316656, 0.999541640282, 0.999705970287, 0.999992847443, 0.687184453011, 0.961265325546, 0.999145627022, 0.999105751514, 0.999160408974, 0.156263574958, 0.989329755306, 0.814526677132, 0.992055594921, 0.95780724287, 0.849580824375, 0.998751521111, 0.998751521111, 0.00202972535, 0.000488866819, 0.000816052023, 0.001193887554, 0.92062073946, 0.997893154621, 0.977864563465, 0.62553948164, 0.000213722626, 4.6143101e-05, 0.017015710473, 0.996939063072, 0.990661919117, 0.903804779053, 0.334248185158, 0.831107616425, 0.831107616425, 0.831107616425, 0.995197117329, 0.090824261308, 0.090421117842, 0.000655344571, 0.032342027873, 0.000319722894, 0.999472677708, 0.986781060696, 0.617120444775, 0.607300043106, 0.624032497406, 0.647029995918, 0.813069760799, 0.51700848341, 0.895080924034, 0.819042205811, 6.913275e-06, 0.000409670552, 0.997803866863, 0.322743445635, 0.864273369312]\n",
      "2116\n",
      "226\n",
      "js-yaml\n",
      "70\n",
      "[0.006904528011, 0.989915907383, 0.623992204666, 0.764240384102, 0.997845411301, 0.99394774437, 0.96419262886, 0.941112875938, 0.986262321472, 0.998886406422, 0.997012615204, 0.998886406422, 0.90806221962, 0.607498645782, 0.999786674976, 0.930754899979, 0.996987402439, 0.859215974808, 0.984716773033, 0.878255724907, 0.993929505348, 0.99881196022, 0.946338951588, 0.957187116146, 0.798501014709, 0.146882295609, 0.933023989201, 0.587370574474, 0.592020213604, 0.993044435978, 0.534558653831, 0.942484080791, 0.967605233192, 0.943161964417, 0.884040415287, 0.993706047535, 0.990031599998, 0.993843078613, 0.996884763241, 0.990316331387, 0.972424030304, 0.993626117706, 0.966680526733, 0.995708703995, 0.985280156136, 0.996476352215, 0.990990638733, 0.945213913918, 0.999414682388, 0.993059277534, 0.930238008499, 0.987394690514, 0.974438428879, 0.990564465523, 0.997334361076, 0.994869112968, 0.999801933765, 0.993998527527, 0.849481642246, 0.998041391373, 0.936465501785, 0.950431346893, 0.996088624001, 0.934822976589, 0.948940753937, 0.998248934746, 0.9982239604]\n",
      "680\n",
      "67\n",
      "express\n",
      "124\n",
      "[0.936913788319, 0.867376863956, 0.988658607006, 0.978825867176, 0.999864220619, 0.999782145023, 0.99553334713, 0.05310293287, 0.98776113987, 0.99439740181, 0.998893082142, 0.992510199547, 0.996402144432, 0.999746501446, 0.999460756779, 0.998463273048, 0.994000554085, 0.987040698528, 0.992906808853, 0.765736997128, 0.999760448933, 0.999834537506, 0.999820053577, 0.999827980995, 0.999838232994, 0.999918103218, 0.999930381775, 0.999934077263, 0.999934792519, 0.985647797585, 0.999864578247, 0.999919176102, 0.999368607998, 0.999089717865, 0.999196588993, 0.968427479267, 0.99907886982, 0.99906462431, 0.999026179314, 0.999208509922, 0.999453604221, 0.999848127365, 0.999847769737, 0.99968457222, 0.999872684479, 0.802274346352, 0.894342958927, 0.993867576122, 0.99925583601, 0.424244523048, 0.424658030272, 0.998615145683, 0.996369838715, 0.999670147896, 0.996983468533, 0.998752474785, 0.998208045959, 0.999330401421, 0.999824225903, 0.999786436558, 0.998083949089, 0.997581481934, 0.999343574047, 0.999849915504, 0.998741447926, 0.999514222145, 0.999476253986, 0.999476015568, 0.999526023865, 0.9997625947, 0.999854922295, 0.99985563755, 0.999845743179, 0.834895551205, 0.999773204327, 0.972311854362, 0.999514818192, 0.99961411953, 0.99961411953, 0.999615311623, 0.999754488468, 0.999764621258, 0.999753892422, 0.999753654003, 0.999879717827, 0.999869704247, 0.999862551689, 0.999869704247, 0.999890446663, 0.999915122986, 0.998078107834, 0.891130805016, 0.999206960201, 0.999871015549, 0.999870538712, 0.999871611595, 0.99987077713, 0.999470055103, 0.999676465988, 0.995189547539, 0.992951214314, 0.993578314781, 0.990953862667, 0.99980121851, 0.999803483486, 0.999816119671, 0.99595451355, 0.998152434826, 0.998514950275, 0.999528408051, 0.999518275261, 0.999491930008, 0.999960541725, 0.999399065971, 0.999338328838, 0.994628608227, 0.999441206455, 0.999751031399, 0.999799668789, 0.04984767735, 0.049847900867, 0.026634532958]\n",
      "1228\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "to_do_list = ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "app_list =  ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "\n",
    "\n",
    "for APPLICATION_NAME in to_do_list:\n",
    "    try:\n",
    "        print(APPLICATION_NAME)\n",
    "        df = pd.read_csv(\"leftout_\"+APPLICATION_NAME+\".csv\")\n",
    "        # print(df)\n",
    "        dst_dict = dict(df.values)\n",
    "\n",
    "        main_lst = []\n",
    "        lst = []\n",
    "        with open(APPLICATION_NAME+\"_missing_edge_log_GatedGCN.txt\", \"r+\") as in_file:\n",
    "            for line in in_file:\n",
    "                if len(line.strip())==0:\n",
    "                    temp_lst =[]\n",
    "                    for x in lst:\n",
    "                        temp_lst.append(x)\n",
    "                    if len(temp_lst)>0:\n",
    "                        main_lst.append(temp_lst)\n",
    "                    lst =[]\n",
    "                else:\n",
    "                    lst.append(line)\n",
    "        count = 0\n",
    "        print(len(main_lst))\n",
    "        rank_lst =[]\n",
    "        all_value_list= []\n",
    "        for lst in main_lst:\n",
    "            node_lst = []\n",
    "            pred_lst = []\n",
    "            for line in lst:\n",
    "                if \"Total edge above\" not in line and \"RANK 1 number of edge\" not in line:\n",
    "                    if 'Source =====>' in line:\n",
    "                        parts = line.split(\" \")\n",
    "                        src = int(parts[-1].strip())\n",
    "                    else:\n",
    "                        parts = line.split(\" \")\n",
    "                        # print(parts)\n",
    "                        dst = int(parts[-3].strip())\n",
    "                        value = float(parts[-1].strip())\n",
    "                        # print(dst, value)\n",
    "                        node_lst.append(dst)\n",
    "                        pred_lst.append(value)\n",
    "            \n",
    "            result_df = pd.DataFrame(list(zip(node_lst, pred_lst)), columns =['id', 'val'])\n",
    "            result_df = result_df.sort_values(by=['val'], ascending=False).reset_index(drop=True)\n",
    "            try:\n",
    "                if len(result_df)>0:\n",
    "                    TARGET = dst_dict[src]\n",
    "                    for i in range(len(result_df)):\n",
    "                        id = result_df.iloc[i]['id']\n",
    "                        if id == TARGET:\n",
    "                            val = result_df.iloc[i]['val']\n",
    "                            rank_lst.append(val)\n",
    "                            found = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            result_df = result_df[:10]\n",
    "            all_value_list+=result_df['val'].tolist()\n",
    "\n",
    "        print(rank_lst)\n",
    "        print(len(all_value_list))\n",
    "\n",
    "            \n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "\n",
    "        # try:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        x = np.arange(0, len(all_value_list),1)\n",
    "        # Create a bar plot using Seaborn\n",
    "        ax = sns.scatterplot(x=x, y=all_value_list)\n",
    "        x2 = np.arange(0,len(rank_lst)*10,10)\n",
    "        print(len(x2))\n",
    "        sns.scatterplot(x=x2, y=rank_lst, label='Scatter Plot 2')\n",
    "        # plt.xticks(range(len(xticks_list)), xticks_list)\n",
    "        plt.title('Histogram of Candidate Ranking')\n",
    "        plt.xlabel('Ranking')\n",
    "        plt.ylabel('Count')\n",
    "        plt.savefig(\"candidate_figures/scatterplot_\"+APPLICATION_NAME+\".pdf\")\n",
    "        plt.close()\n",
    "        # except:\n",
    "        #     pass\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e89920",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do_list = ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "app_list =  ['formula-parser', 'lodash', 'js-yaml','express']\n",
    "\n",
    "MODEL_NAME = 'GatedGCN'\n",
    "for APPLICATION_NAME in to_do_list:\n",
    "    try:\n",
    "        print(APPLICATION_NAME)\n",
    "        main_lst = []\n",
    "        lst = []\n",
    "        PATH = \"results/NEW_DATASET--\"+APPLICATION_NAME+\"/\"+MODEL_NAME\n",
    "        EPOC_NUMBER = get_EPOC_Number(PATH=PATH)\n",
    "        print(PATH)\n",
    "        with open(APPLICATION_NAME+\"_missing_edge_log_GatedGCN_with_epoc_\"+str(EPOC_NUMBER)+\"_new.txt\", \"r+\") as in_file:\n",
    "            for line in in_file:\n",
    "                if len(line.strip())==0:\n",
    "                    temp_lst =[]\n",
    "                    for x in lst:\n",
    "                        temp_lst.append(x)\n",
    "                    if len(temp_lst)>0:\n",
    "                        main_lst.append(temp_lst)\n",
    "                    lst =[]\n",
    "                else:\n",
    "                    lst.append(line)\n",
    "        count = 0\n",
    "        print(len(main_lst))\n",
    "        rank_lst =[]\n",
    "        all_value_list= []\n",
    "        for lst in main_lst:\n",
    "            node_lst = []\n",
    "            pred_lst = []\n",
    "            for line in lst:\n",
    "                if \"Total\" not in line and \"RANK 1 number of edge\" not in line:\n",
    "                    if 'Source =====>' in line:\n",
    "                        parts = line.split(\" \")\n",
    "                        src = int(parts[-1].strip())\n",
    "                    else:\n",
    "                        parts = line.split(\" \")\n",
    "                        # print(parts)\n",
    "                        dst = int(parts[-3].strip())\n",
    "                        value = float(parts[-1].strip())\n",
    "                        # print(dst, value)\n",
    "                        node_lst.append(dst)\n",
    "                        pred_lst.append(value)\n",
    "            \n",
    "            result_df = pd.DataFrame(list(zip(node_lst, pred_lst)), columns =['id', 'val'])\n",
    "            result_df = result_df.sort_values(by=['val'], ascending=False).reset_index(drop=True)\n",
    "            result_df = result_df[:10]\n",
    "            all_value_list+=result_df['val'].tolist()\n",
    "\n",
    "        # print(rank_lst)\n",
    "        # print(len(all_value_list))\n",
    "\n",
    "            \n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "\n",
    "        # try:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        x = np.arange(0, len(all_value_list),1)\n",
    "        # Create a bar plot using Seaborn\n",
    "        ax = sns.scatterplot(x=x, y=all_value_list)\n",
    "        # sns.histplot(all_value_list, kde=True, bins=10)\n",
    "        # sns.kdeplot(all_value_list, shade=True)\n",
    "        # plt.xticks(range(len(xticks_list)), xticks_list)\n",
    "        plt.title('Histogram of Candidate Ranking')\n",
    "        plt.xlabel('Ranking')\n",
    "        plt.ylabel('Count')\n",
    "        plt.savefig(\"candidate_figures/missing_scatterplot_\"+APPLICATION_NAME+\".pdf\")\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "        # except:\n",
    "        #     pass\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4589</td>\n",
       "      <td>9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9543</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9544</td>\n",
       "      <td>2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9545</td>\n",
       "      <td>2742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9556</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>4589</td>\n",
       "      <td>23250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>23259</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>23260</td>\n",
       "      <td>2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>23260</td>\n",
       "      <td>2635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>4589</td>\n",
       "      <td>23261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       src    dst\n",
       "0     4589   9535\n",
       "1     9543   2872\n",
       "2     9544   2732\n",
       "3     9545   2742\n",
       "4     9556   2872\n",
       "..     ...    ...\n",
       "942   4589  23250\n",
       "943  23259   2872\n",
       "944  23260   2605\n",
       "945  23260   2635\n",
       "946   4589  23261\n",
       "\n",
       "[947 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df = pd.read_csv(\"results/NEW_DATASET--express\"+\"/GatedGCN/POS_PRED/pred_score_with_0_pos.csv\", header=None)\n",
    " df.columns = ['src', 'dst', 'prob']\n",
    " df = df.drop(['prob'], axis=1)\n",
    " df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4847</td>\n",
       "      <td>5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4852</td>\n",
       "      <td>5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3147</td>\n",
       "      <td>3299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3179</td>\n",
       "      <td>3299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3183</td>\n",
       "      <td>3299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>9520</td>\n",
       "      <td>2742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>4589</td>\n",
       "      <td>9521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>9531</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>9532</td>\n",
       "      <td>2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>9534</td>\n",
       "      <td>2742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3785 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       src   dst\n",
       "0     4847  5004\n",
       "1     4852  5004\n",
       "2     3147  3299\n",
       "3     3179  3299\n",
       "4     3183  3299\n",
       "...    ...   ...\n",
       "3780  9520  2742\n",
       "3781  4589  9521\n",
       "3782  9531  2872\n",
       "3783  9532  2732\n",
       "3784  9534  2742\n",
       "\n",
       "[3785 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_edges = pd.read_csv(\"dynamic_edges/prune_dynamic_edges_\"+\"express.csv\")\n",
    "dynamic_edges = dynamic_edges.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "df = pd.read_csv(\"results/NEW_DATASET--\"+\"express/GatedGCN/POS_PRED/pred_score_with_0_pos.csv\", header=None)\n",
    "df.columns = ['src', 'dst', 'prob']\n",
    "df = df.drop(['prob'], axis=1)\n",
    "dynamic_edges = dynamic_edges.merge(df, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "dynamic_edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
